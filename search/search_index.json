{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Daily Devloping Guide \u00b6 This is a guide site for daily developing. index \u00b6 Home Language Python SQL Unix Commands & Bash Server Nginx Supervisor Mkdocs Django Airflow","title":"Home"},{"location":"#daily-devloping-guide","text":"This is a guide site for daily developing.","title":"Daily Devloping Guide"},{"location":"#index","text":"Home Language Python SQL Unix Commands & Bash Server Nginx Supervisor Mkdocs Django Airflow","title":"index"},{"location":"about/","text":"Zonam amantes excusat aliisque loqui totoque \u00b6 At levat meque magni non Iove crimine \u00b6 Lorem markdownum parentem vident sed esse pressam. Discedere rogantis recedere; mihi odissem, et status trahit Saturnia caelo votis reges talisque, crura? Manus vacuo violentaque laudis quem vel atque formam. Et clipeum corpora. var code_dvi = cybersquatter_ring_terminal; var dhcpDnsDigital = impact_matrix; if (impactNat + 2 <= kilohertzMiniSdram + runtime) { dbms.realJreMamp(cd_symbolic_boot); wimaxSystrayBlu.isp_drive_nic(5, 97, viral); process = www_plagiarism; } else { primaryBox(png, loadSerpLossless, and_tablet_deprecated(point, -5, delThreadSmtp)); panel += worm; memory(soft_switch_shortcut.panel_address_big(icq, 4, controllerLeft), formatGopher.language.menuDrop(networkUnmountManet, volume_user, view_floating)); } Esset sedet tenetur \u00b6 Quantusque posita misit totoque quaeque, nunc edere o feris mea properent ut tamen ! Contulerant hunc; cecidere libertas. Quoque et utero additur coniunx \u00b6 Crimen sonantes certo patrium inexorabile nisi Troas, Tegeaea et nempe, spectantis. Pedes finierat laudatis et conubia publica oris perspicit potestis prope. Nec terris \u00b6 Sibi eburno adspexit duplex: exigite candor effecisse? Colli molliaque piacula posse exclamat orbis indignatur dei velocibus, qui habuit pervia. Cortice navigat illo probabit. if (mouse_association_card + drive * tiff) { menuTrackball = -5; promptTrinitron = ip_oop; file = onlinePostFile(botnetMinicomputerError, 4, baud_hexadecimal_install) + mbr; } else { mips.gps = icq + 3; } engine = workstationSaas.document(codecFileClob * ipPinterestMountain + syntaxKeyApp, sd * cpa_formula); hoverUp.dot_portal_spoofing += interlacedDocking(host_parallel(us - ppl, superscalar_scroll_mask, 12)); Vara durasse \u00b6 Ades conata ubi procumbit protinus Priamoque quippe pectora veteris : herbas rustica, tuum et. Factus vetuit, est vindice vescitur. Habet despectabat velamine, gelidos dederatque dederat. In cava, de exspirat superamur omnia, sulcum sequentis luctatur : pete aptabat muneris arreptamque remige adspicit. Negarem ab non illos adsiduis: et dominum laedam, si illud amissam discite Nereia fraterno et opus adiuvat percurrere. Gravatum dedisset factisque rostrum caput. Coniugis e placet nescis; ora pariter nomen est dolor, casu. Cibos opesque plura aut est currum mutua vindicet gradus virum, capillis famamque erat: equidem. Satis in Clytumque pedem qui quaecumque, consternatique canities Italiae concidit caelum primum duro viderat vixque!","title":"Zonam amantes excusat aliisque loqui totoque"},{"location":"about/#zonam-amantes-excusat-aliisque-loqui-totoque","text":"","title":"Zonam amantes excusat aliisque loqui totoque"},{"location":"about/#at-levat-meque-magni-non-iove-crimine","text":"Lorem markdownum parentem vident sed esse pressam. Discedere rogantis recedere; mihi odissem, et status trahit Saturnia caelo votis reges talisque, crura? Manus vacuo violentaque laudis quem vel atque formam. Et clipeum corpora. var code_dvi = cybersquatter_ring_terminal; var dhcpDnsDigital = impact_matrix; if (impactNat + 2 <= kilohertzMiniSdram + runtime) { dbms.realJreMamp(cd_symbolic_boot); wimaxSystrayBlu.isp_drive_nic(5, 97, viral); process = www_plagiarism; } else { primaryBox(png, loadSerpLossless, and_tablet_deprecated(point, -5, delThreadSmtp)); panel += worm; memory(soft_switch_shortcut.panel_address_big(icq, 4, controllerLeft), formatGopher.language.menuDrop(networkUnmountManet, volume_user, view_floating)); }","title":"At levat meque magni non Iove crimine"},{"location":"about/#esset-sedet-tenetur","text":"Quantusque posita misit totoque quaeque, nunc edere o feris mea properent ut tamen ! Contulerant hunc; cecidere libertas.","title":"Esset sedet tenetur"},{"location":"about/#quoque-et-utero-additur-coniunx","text":"Crimen sonantes certo patrium inexorabile nisi Troas, Tegeaea et nempe, spectantis. Pedes finierat laudatis et conubia publica oris perspicit potestis prope.","title":"Quoque et utero additur coniunx"},{"location":"about/#nec-terris","text":"Sibi eburno adspexit duplex: exigite candor effecisse? Colli molliaque piacula posse exclamat orbis indignatur dei velocibus, qui habuit pervia. Cortice navigat illo probabit. if (mouse_association_card + drive * tiff) { menuTrackball = -5; promptTrinitron = ip_oop; file = onlinePostFile(botnetMinicomputerError, 4, baud_hexadecimal_install) + mbr; } else { mips.gps = icq + 3; } engine = workstationSaas.document(codecFileClob * ipPinterestMountain + syntaxKeyApp, sd * cpa_formula); hoverUp.dot_portal_spoofing += interlacedDocking(host_parallel(us - ppl, superscalar_scroll_mask, 12));","title":"Nec terris"},{"location":"about/#vara-durasse","text":"Ades conata ubi procumbit protinus Priamoque quippe pectora veteris : herbas rustica, tuum et. Factus vetuit, est vindice vescitur. Habet despectabat velamine, gelidos dederatque dederat. In cava, de exspirat superamur omnia, sulcum sequentis luctatur : pete aptabat muneris arreptamque remige adspicit. Negarem ab non illos adsiduis: et dominum laedam, si illud amissam discite Nereia fraterno et opus adiuvat percurrere. Gravatum dedisset factisque rostrum caput. Coniugis e placet nescis; ora pariter nomen est dolor, casu. Cibos opesque plura aut est currum mutua vindicet gradus virum, capillis famamque erat: equidem. Satis in Clytumque pedem qui quaecumque, consternatique canities Italiae concidit caelum primum duro viderat vixque!","title":"Vara durasse"},{"location":"detail/","text":"Detail \u00b6","title":"Detail"},{"location":"detail/#detail","text":"","title":"Detail"},{"location":"data/chart/","text":"Chart \u00b6 Scatter Chart tops = report1 [: 100 ] xlabel = \"xLabel\" ylabel = \"yLabel\" x = tops [ xlabel ] y = tops [ ylabel ] s = tops [ 'index' ] texts = tops . index fig , ax = plt . subplots ( figsize = ( 40 , 20 )) ax . scatter ( x , y , s = s ) plt . xlabel ( xlabel ) plt . ylabel ( ylabel ) exists = [] for i , txt in enumerate ( texts ): loc = ( x [ i ], y [ i ]) ax . annotate ( txt , loc ) exists . append ( loc ) Display utf-8 character in matplorlib chart from matplotlib.font_manager import FontProperties from matplotlib import pyplot as plt font = FontProperties ( fname = \"c:/windows/fonts/simsun.ttc\" , size = 14 ) plt . title ( \"\u767e\u5206\u4f4d\u56fe\" , fontproperties = font ) plt . xticks ( fontproperties = font ) Display utf-8 character in Graphviz chart 1. Set fonts.conf in Graphviz. 2. Change souce format as gbk in python graphviz. 3. Add `node[fontname = \"PMingLiu\"];` in dot file.","title":"Chart"},{"location":"data/chart/#chart","text":"Scatter Chart tops = report1 [: 100 ] xlabel = \"xLabel\" ylabel = \"yLabel\" x = tops [ xlabel ] y = tops [ ylabel ] s = tops [ 'index' ] texts = tops . index fig , ax = plt . subplots ( figsize = ( 40 , 20 )) ax . scatter ( x , y , s = s ) plt . xlabel ( xlabel ) plt . ylabel ( ylabel ) exists = [] for i , txt in enumerate ( texts ): loc = ( x [ i ], y [ i ]) ax . annotate ( txt , loc ) exists . append ( loc ) Display utf-8 character in matplorlib chart from matplotlib.font_manager import FontProperties from matplotlib import pyplot as plt font = FontProperties ( fname = \"c:/windows/fonts/simsun.ttc\" , size = 14 ) plt . title ( \"\u767e\u5206\u4f4d\u56fe\" , fontproperties = font ) plt . xticks ( fontproperties = font ) Display utf-8 character in Graphviz chart 1. Set fonts.conf in Graphviz. 2. Change souce format as gbk in python graphviz. 3. Add `node[fontname = \"PMingLiu\"];` in dot file.","title":"Chart"},{"location":"data/dataProcessing/","text":"Data processing \u00b6 The goal \u00b6 Convert the data close to nature, and make more convenient for human and computer to understand the data. Common method \u00b6 Data cleaning: process the missing value and wrong data Data integration: intergate data from multiple sources. Data reduction: vector reduction and value reduction Data transformation: standardization, log transformation, discretization Data mixing: reduce the problem caused by data order Specific method \u00b6 Use log transformation to process nonlinear data \u00b6 In addition, there are power transformation, negative transformation and root transformation, all of which are data transformations. Log transformation is useful to conver many data multiply to add, which avoid influence of value close to 0. And it is convenient to calculate. If you need make 2 and 0.5 has a equal range from 1, using natural logarithm \"e\" will get a result of 0.69 and -0.69. Avoid predicting past target variables with future feature variables in time series data. \u00b6 Discretization for multimodal distribution variable \u00b6 Principal Component Analysis \u00b6 \u00b6 Ptyhon sklearn processing library: preprocessing \u00b6 Referral \u00b6 [Data Mining Concepts and Techiques]","title":"Data processing"},{"location":"data/dataProcessing/#data-processing","text":"","title":"Data processing"},{"location":"data/dataProcessing/#the-goal","text":"Convert the data close to nature, and make more convenient for human and computer to understand the data.","title":"The goal"},{"location":"data/dataProcessing/#common-method","text":"Data cleaning: process the missing value and wrong data Data integration: intergate data from multiple sources. Data reduction: vector reduction and value reduction Data transformation: standardization, log transformation, discretization Data mixing: reduce the problem caused by data order","title":"Common method"},{"location":"data/dataProcessing/#specific-method","text":"","title":"Specific method"},{"location":"data/dataProcessing/#use-log-transformation-to-process-nonlinear-data","text":"In addition, there are power transformation, negative transformation and root transformation, all of which are data transformations. Log transformation is useful to conver many data multiply to add, which avoid influence of value close to 0. And it is convenient to calculate. If you need make 2 and 0.5 has a equal range from 1, using natural logarithm \"e\" will get a result of 0.69 and -0.69.","title":"Use log transformation to process nonlinear data"},{"location":"data/dataProcessing/#avoid-predicting-past-target-variables-with-future-feature-variables-in-time-series-data","text":"","title":"Avoid predicting past target variables with future feature variables  in time series data."},{"location":"data/dataProcessing/#discretization-for-multimodal-distribution-variable","text":"","title":"Discretization for multimodal distribution variable"},{"location":"data/dataProcessing/#principal-component-analysis","text":"","title":"Principal Component Analysis"},{"location":"data/dataProcessing/#ptyhon-sklearn-processing-library-preprocessing","text":"","title":"Ptyhon sklearn processing library: preprocessing"},{"location":"data/dataProcessing/#referral","text":"[Data Mining Concepts and Techiques]","title":"Referral"},{"location":"language/css/","text":"CSS \u00b6 MDN Doc Layout \u00b6 layout = box model + display + position + float / clear Box model \u00b6 Rule1: All block element is a rectangle block. Rule2 element.width = content.width + element.padding + element.border + element.margin Rule3 if element . width is None : element . width = parentElement . width Rule4 content.width = element.width - element.padding - element.border - element.margin Rule5: width(css) != element.width width(css) = content.width Display \u00b6 inline \u00b6 <a>, <span>, <b>, <em>, <i>, <cite>, <mark>, and <code>. Text based elements. Ignore width and height attributes. The top and bottom margins cannot be set. You can set the left and right margins and all the inner margins. If you use the float attribute, it becomes a block-level element. Can use white-space and vertical-align properties. Arranged after the previous text by default. Except for which can be placed on block-level elements, other inline elements cannot be placed on block-level elements. block \u00b6 <div>, <p> Structure-based elements. Can control width and height. If the width is not set, the width will expand to the width of the parent element. If no height is set, the height will be expanded as the child element expands Can set padding and padding Ignore the vertical-align property. Arranged below the previous element by default. flex \u00b6 For flex element: set main axis: flex-direction set is wrap for multiline: flex-wrap main axis align: justify-content cross axis align: align-items /* Normal version */ { display : flex ; /* flex-direction: row|row-reverse|column|column-reverse */ flex-direction : row ; /* flex-wrap: wrap/no-wrap */ flex-wrap : wrap ; /* justify-content: flex-start|flex-end|center|space-around|space-between|space-evenly */ justify-content : center ; /* align-items: stretch|flex-start|flex-end|center */ align-items : center ; } /* Short version */ { display : flex ; flex-flow : row wrap center center ; } For flex childItems: flex-grow: additional space assigned when sum(childItems.width) < parentElement.width flex-shrink: shrink size when sum(childItems.width) < parentElement.width flex-basis: initial main size of a flex item(replace witdth ) childItem.finalSize = flex-basi * flex-grow * flex-shrink { /* 0|1|2 */ flex-grow : 1 ; /* 0|1|2 */ flex-shrink : 1 ; /* auto|10px */ flex-basis : auto ; } /* Short version */ { flex : 1 , 1 , auto ; } Position \u00b6 realtive: from self absolute: from parent element fixed: from browser window Float and clear \u00b6","title":"CSS"},{"location":"language/css/#css","text":"MDN Doc","title":"CSS"},{"location":"language/css/#layout","text":"layout = box model + display + position + float / clear","title":"Layout"},{"location":"language/css/#box-model","text":"Rule1: All block element is a rectangle block. Rule2 element.width = content.width + element.padding + element.border + element.margin Rule3 if element . width is None : element . width = parentElement . width Rule4 content.width = element.width - element.padding - element.border - element.margin Rule5: width(css) != element.width width(css) = content.width","title":"Box model"},{"location":"language/css/#display","text":"","title":"Display"},{"location":"language/css/#inline","text":"<a>, <span>, <b>, <em>, <i>, <cite>, <mark>, and <code>. Text based elements. Ignore width and height attributes. The top and bottom margins cannot be set. You can set the left and right margins and all the inner margins. If you use the float attribute, it becomes a block-level element. Can use white-space and vertical-align properties. Arranged after the previous text by default. Except for which can be placed on block-level elements, other inline elements cannot be placed on block-level elements.","title":"inline"},{"location":"language/css/#block","text":"<div>, <p> Structure-based elements. Can control width and height. If the width is not set, the width will expand to the width of the parent element. If no height is set, the height will be expanded as the child element expands Can set padding and padding Ignore the vertical-align property. Arranged below the previous element by default.","title":"block"},{"location":"language/css/#flex","text":"For flex element: set main axis: flex-direction set is wrap for multiline: flex-wrap main axis align: justify-content cross axis align: align-items /* Normal version */ { display : flex ; /* flex-direction: row|row-reverse|column|column-reverse */ flex-direction : row ; /* flex-wrap: wrap/no-wrap */ flex-wrap : wrap ; /* justify-content: flex-start|flex-end|center|space-around|space-between|space-evenly */ justify-content : center ; /* align-items: stretch|flex-start|flex-end|center */ align-items : center ; } /* Short version */ { display : flex ; flex-flow : row wrap center center ; } For flex childItems: flex-grow: additional space assigned when sum(childItems.width) < parentElement.width flex-shrink: shrink size when sum(childItems.width) < parentElement.width flex-basis: initial main size of a flex item(replace witdth ) childItem.finalSize = flex-basi * flex-grow * flex-shrink { /* 0|1|2 */ flex-grow : 1 ; /* 0|1|2 */ flex-shrink : 1 ; /* auto|10px */ flex-basis : auto ; } /* Short version */ { flex : 1 , 1 , auto ; }","title":"flex"},{"location":"language/css/#position","text":"realtive: from self absolute: from parent element fixed: from browser window","title":"Position"},{"location":"language/css/#float-and-clear","text":"","title":"Float and clear"},{"location":"language/python/","text":"Install \u00b6 Centos \u00b6 https://janikarhunen.fi/how-to-install-python-3-6-1-on-centos-7 Ubuntu \u00b6 Use ppa (Personal Package Archive) sudo add-apt-repository ppa:deadsnakes/ppa sudo apt-get update sudo apt-get install python3.6 Install the necessary libraries \u00b6 pip: https://pip.pypa.io/en/stable/installing/ Virtualenv: pip install virtualenv Admin \u00b6 Package install \u00b6 Pip from image source(Tempoary setting) pip install -I https://pypi.douban.com/simple/ Pip from image source(Persistence setting): edit \\$HOME/.pip/pip.conf(Unix) or %HOME%\\pip\\pip.ini(Windows) add [global] timeout = 6000 index-url = http://pypi.douban.com/simple trusted-host = pypi.douban.com Virtualenv \u00b6 Create virtualenv with specified version virtualenv env -p /usr/bin/python3.7 # or Python -m venv env Path \u00b6 Alias python name alias python=python3.7 This command can't run use sudo , because it is a user level command. Code Sample \u00b6 Get current script location scriptLocation = os . path . dirname ( os . path . realpath ( __file__ )) Get current local datetime time_str = time . strftime ( '%Y-%m- %d %H%m%S' , time . localtime ()) Export xlsx without url format with pd . ExcelWriter ( filepath , engine = 'xlsxwriter' , options = { 'strings_to_urls' : False }) as writer : df . to_excel ( writer , index = False ) Save excel-readabel csv with utf-8 resultFilepath = \"result.csv\" with open ( resultFilepath , mode = \"w\" , encoding = \"utf-8\" ) as f : f . write ( ' \\ufeff ' ) result . to_csv ( f , index = False , line_terminator = ' \\n ' ) Sort by a list [ x for _ , x in sorted ( zip ( Y , X ))] Quickly understand the information redundancy of pandas dataframe { x : df [ x ] . duplicated () . sum () / df . shape [ 0 ] for x in df . columns } Vertical Cmobine two array np . vstack (( x . T , y . T )) . T Descorate for func with arguements def catchKeyboardInterrupt ( func , * args , ** kwargs ): def wapper ( * args , ** kwargs ): try : result = func ( * args , ** kwargs ) except KeyboardInterrupt : sys . exit () return result return wapper OOP \u00b6 Static method vs class method \u00b6 Static method can be used before class init. Recommend Project File Structure \u00b6 projectName projectName assets database.db static mystyle.css rule.js templates layout.html common io.py setting.py componentName module1.py module2.py module3.py tools.py componentName module1.py module2.py module3.py tools.py main.py tests test_main.py test_components_module1.py run.py otherAction.py readme.md Script main.py is script for refered, not not for run. Script under every components is mutually independant.The common part should saved under common folder. Folder assets is Used to save various data. Debug \u00b6 Microsoft Visual C++ 14.0 is required \u00b6 visit https://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml and download compiled package Croniter error when install Django \u00b6 Version 0.3.26 and 0.3.27 is not exists at croniter, modify version(like 0.3.28) at requirements.txt Setup \u00b6 Setup program is used for install at different enviroment and make it can be install by other peoples. The standard library for setup in Python is setuptools . A complete route for setup is: \u00b6 Add setup.py \u00b6 Project information: name, version, author, author_email Assoiate packages:packages Entry points for commmand line tool:entry_points from setuptools import setup , find_packages setup ( name = \"package\" , version = \"0.1\" , author = \"Brendon Lin\" , author_email = \"brendon.lin@outlook.com\" , description = \"Package for setup\" , packages = find_packages (), install_requires = [ \"loguru>=0.4.1\" ], entry_points = { \"console_scripts\" : [ \"runit = package.view:main\" ]}, ) Add other files \u00b6 introduce file: Readme.md license file: LICENSE . The license can be selected from Here . Build package \u00b6 pip install -U setuptools wheel python setup.py sdist bdist_wheel # Then two file will found under `dist/`,with two file formats: tar.gz and wheel.The latter one being the more preferred format for the new pip. Upload package \u00b6 Regist account at pypi Install twine: pip install twine Upload: python -m twine upload dist/* Tips \u00b6 Install by setup.py: python setup.py install Argparse \u00b6 Official Guide Official Tutrial Sample import argparse parser = argparse . ArgumentParser ( description = 'Process some integers.' ) parser . add_argument ( 'integers' , metavar = 'N' , type = int , nargs = '+' , help = 'an integer for the accumulator' ) parser . add_argument ( '--sum' , dest = 'accumulate' , action = 'store_const' , const = sum , default = max , help = 'sum the integers (default: find the max)' ) args = parser . parse_args () print ( args . accumulate ( args . integers )) Parameter of add_argument: name or flags - Either a name or a list of option strings, e.g. foo or -f,--foo. action - The basic type of action to be taken when this argument is encountered at the command line. nargs - The number of command-line arguments that should be consumed. const - A constant value required by some action and nargs selections. default - The value produced if the argument is absent from the command line. type - The type to which the command-line argument should be converted. choices - A container of the allowable values for the argument. required - Whether or not the command-line option may be omitted (optionals only). help - A brief description of what the argument does. metavar - A name for the argument in usage messages. dest - The name of the attribute to be added to the object returned by * parse_args(). Command arguements types \u00b6 Positional arguments\uff1arequired parameter, like normal param in function. Optional arguments\uff1alike keyword param in funciton\uff0cUse prefix with -- or - .Default value is None\u3002It is not the same as a placeholder parameter. If you write it, you must write the parameter name and then add the parameter value. If the expectation is to use no parameter value, just to represent a switch, you can use action = \"make_true\" to implement it. Short options\uff1aSimple version of optional parameters, just add an abbreviation symbol in front of the optional parameters # Optional arguments parser . add_argument ( \"--verbose\" , help = \"increase output verbosity\" ) # Optional arguments not need argment value parser . add_argument ( \"--verbose\" , help = \"increase output verbosity\" , action = \"store_true\" ) # Optional arguments short version parser . add_argument ( \"-v\" , \"--verbose\" , help = \"increase output verbosity\" , action = \"store_true\" )","title":"Python"},{"location":"language/python/#install","text":"","title":"Install"},{"location":"language/python/#centos","text":"https://janikarhunen.fi/how-to-install-python-3-6-1-on-centos-7","title":"Centos"},{"location":"language/python/#ubuntu","text":"Use ppa (Personal Package Archive) sudo add-apt-repository ppa:deadsnakes/ppa sudo apt-get update sudo apt-get install python3.6","title":"Ubuntu"},{"location":"language/python/#install-the-necessary-libraries","text":"pip: https://pip.pypa.io/en/stable/installing/ Virtualenv: pip install virtualenv","title":"Install the necessary libraries"},{"location":"language/python/#admin","text":"","title":"Admin"},{"location":"language/python/#package-install","text":"Pip from image source(Tempoary setting) pip install -I https://pypi.douban.com/simple/ Pip from image source(Persistence setting): edit \\$HOME/.pip/pip.conf(Unix) or %HOME%\\pip\\pip.ini(Windows) add [global] timeout = 6000 index-url = http://pypi.douban.com/simple trusted-host = pypi.douban.com","title":"Package install"},{"location":"language/python/#virtualenv","text":"Create virtualenv with specified version virtualenv env -p /usr/bin/python3.7 # or Python -m venv env","title":"Virtualenv"},{"location":"language/python/#path","text":"Alias python name alias python=python3.7 This command can't run use sudo , because it is a user level command.","title":"Path"},{"location":"language/python/#code-sample","text":"Get current script location scriptLocation = os . path . dirname ( os . path . realpath ( __file__ )) Get current local datetime time_str = time . strftime ( '%Y-%m- %d %H%m%S' , time . localtime ()) Export xlsx without url format with pd . ExcelWriter ( filepath , engine = 'xlsxwriter' , options = { 'strings_to_urls' : False }) as writer : df . to_excel ( writer , index = False ) Save excel-readabel csv with utf-8 resultFilepath = \"result.csv\" with open ( resultFilepath , mode = \"w\" , encoding = \"utf-8\" ) as f : f . write ( ' \\ufeff ' ) result . to_csv ( f , index = False , line_terminator = ' \\n ' ) Sort by a list [ x for _ , x in sorted ( zip ( Y , X ))] Quickly understand the information redundancy of pandas dataframe { x : df [ x ] . duplicated () . sum () / df . shape [ 0 ] for x in df . columns } Vertical Cmobine two array np . vstack (( x . T , y . T )) . T Descorate for func with arguements def catchKeyboardInterrupt ( func , * args , ** kwargs ): def wapper ( * args , ** kwargs ): try : result = func ( * args , ** kwargs ) except KeyboardInterrupt : sys . exit () return result return wapper","title":"Code Sample"},{"location":"language/python/#oop","text":"","title":"OOP"},{"location":"language/python/#static-method-vs-class-method","text":"Static method can be used before class init.","title":"Static method vs class method"},{"location":"language/python/#recommend-project-file-structure","text":"projectName projectName assets database.db static mystyle.css rule.js templates layout.html common io.py setting.py componentName module1.py module2.py module3.py tools.py componentName module1.py module2.py module3.py tools.py main.py tests test_main.py test_components_module1.py run.py otherAction.py readme.md Script main.py is script for refered, not not for run. Script under every components is mutually independant.The common part should saved under common folder. Folder assets is Used to save various data.","title":"Recommend Project File Structure"},{"location":"language/python/#debug","text":"","title":"Debug"},{"location":"language/python/#microsoft-visual-c-140-is-required","text":"visit https://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml and download compiled package","title":"Microsoft Visual C++ 14.0 is required"},{"location":"language/python/#croniter-error-when-install-django","text":"Version 0.3.26 and 0.3.27 is not exists at croniter, modify version(like 0.3.28) at requirements.txt","title":"Croniter error when install Django"},{"location":"language/python/#setup","text":"Setup program is used for install at different enviroment and make it can be install by other peoples. The standard library for setup in Python is setuptools .","title":"Setup"},{"location":"language/python/#a-complete-route-for-setup-is","text":"","title":"A complete route for setup is:"},{"location":"language/python/#add-setuppy","text":"Project information: name, version, author, author_email Assoiate packages:packages Entry points for commmand line tool:entry_points from setuptools import setup , find_packages setup ( name = \"package\" , version = \"0.1\" , author = \"Brendon Lin\" , author_email = \"brendon.lin@outlook.com\" , description = \"Package for setup\" , packages = find_packages (), install_requires = [ \"loguru>=0.4.1\" ], entry_points = { \"console_scripts\" : [ \"runit = package.view:main\" ]}, )","title":"Add setup.py"},{"location":"language/python/#add-other-files","text":"introduce file: Readme.md license file: LICENSE . The license can be selected from Here .","title":"Add other files"},{"location":"language/python/#build-package","text":"pip install -U setuptools wheel python setup.py sdist bdist_wheel # Then two file will found under `dist/`,with two file formats: tar.gz and wheel.The latter one being the more preferred format for the new pip.","title":"Build package"},{"location":"language/python/#upload-package","text":"Regist account at pypi Install twine: pip install twine Upload: python -m twine upload dist/*","title":"Upload package"},{"location":"language/python/#tips","text":"Install by setup.py: python setup.py install","title":"Tips"},{"location":"language/python/#argparse","text":"Official Guide Official Tutrial Sample import argparse parser = argparse . ArgumentParser ( description = 'Process some integers.' ) parser . add_argument ( 'integers' , metavar = 'N' , type = int , nargs = '+' , help = 'an integer for the accumulator' ) parser . add_argument ( '--sum' , dest = 'accumulate' , action = 'store_const' , const = sum , default = max , help = 'sum the integers (default: find the max)' ) args = parser . parse_args () print ( args . accumulate ( args . integers )) Parameter of add_argument: name or flags - Either a name or a list of option strings, e.g. foo or -f,--foo. action - The basic type of action to be taken when this argument is encountered at the command line. nargs - The number of command-line arguments that should be consumed. const - A constant value required by some action and nargs selections. default - The value produced if the argument is absent from the command line. type - The type to which the command-line argument should be converted. choices - A container of the allowable values for the argument. required - Whether or not the command-line option may be omitted (optionals only). help - A brief description of what the argument does. metavar - A name for the argument in usage messages. dest - The name of the attribute to be added to the object returned by * parse_args().","title":"Argparse"},{"location":"language/python/#command-arguements-types","text":"Positional arguments\uff1arequired parameter, like normal param in function. Optional arguments\uff1alike keyword param in funciton\uff0cUse prefix with -- or - .Default value is None\u3002It is not the same as a placeholder parameter. If you write it, you must write the parameter name and then add the parameter value. If the expectation is to use no parameter value, just to represent a switch, you can use action = \"make_true\" to implement it. Short options\uff1aSimple version of optional parameters, just add an abbreviation symbol in front of the optional parameters # Optional arguments parser . add_argument ( \"--verbose\" , help = \"increase output verbosity\" ) # Optional arguments not need argment value parser . add_argument ( \"--verbose\" , help = \"increase output verbosity\" , action = \"store_true\" ) # Optional arguments short version parser . add_argument ( \"-v\" , \"--verbose\" , help = \"increase output verbosity\" , action = \"store_true\" )","title":"Command arguements types"},{"location":"language/sql/","text":"SQL \u00b6 Code sample \u00b6 Create table CREATE TABLE tablex ( field1 varchar ( 20 ), field2 char ( 1 )); Create index CREATE INDEX index_name ON tablex ( field1 ); Delete index ALTER TABLE tablex DROP INDEX index_name Insert rows INSERT INTO tablex VALUES ( \"xx\" , \"1\" ); Update values UPDATE TABLE tablex SET field1 = \"\" WHERE field2 = \"m\" ; Delete rows DELETE FROM tablex WHERE field2 = \"m\" ; Delete table DROP TABLE tablex ; Debug \u00b6 Diffrence between union and union all \u00b6 The union will delete duplicate rows but union all not. Referral \u00b6 Impala SQL Spark SQL Pyspark.sql PostgreSQL SQLServer2017 SQlite SQL core functions MySQL","title":"SQL"},{"location":"language/sql/#sql","text":"","title":"SQL"},{"location":"language/sql/#code-sample","text":"Create table CREATE TABLE tablex ( field1 varchar ( 20 ), field2 char ( 1 )); Create index CREATE INDEX index_name ON tablex ( field1 ); Delete index ALTER TABLE tablex DROP INDEX index_name Insert rows INSERT INTO tablex VALUES ( \"xx\" , \"1\" ); Update values UPDATE TABLE tablex SET field1 = \"\" WHERE field2 = \"m\" ; Delete rows DELETE FROM tablex WHERE field2 = \"m\" ; Delete table DROP TABLE tablex ;","title":"Code sample"},{"location":"language/sql/#debug","text":"","title":"Debug"},{"location":"language/sql/#diffrence-between-union-and-union-all","text":"The union will delete duplicate rows but union all not.","title":"Diffrence between union and union all"},{"location":"language/sql/#referral","text":"Impala SQL Spark SQL Pyspark.sql PostgreSQL SQLServer2017 SQlite SQL core functions MySQL","title":"Referral"},{"location":"language/unix_commnads_bash/","text":"Unix Commands & Bash \u00b6 Unix Commands \u00b6 Samples \u00b6 Remove files under folder rm -rf /path/to/directory/* Count the number of files ls wc -l IP test curl ifconfig.me Search process by keyword ps -ef | grep {keyword} Search file by keyword ls {folder path} | grep {keyword} ls sort by size ls -ls -h -S Search log info by keyword cat {log file path} | grep {keyword} Libraries \u00b6 Memory view: atop Kill process by keyword: pkill -f supervisord Referral \u00b6 Basic UNIX commands Bash \u00b6 Bash scripting cheatsheet User management \u00b6 Referral \u00b6 Ubuntu File Permissions Ubuntu User Management Useful commands \u00b6 Modify permission of file: chmod u+x filePath Add user to group: sudo adduser username groupname Check all user: cat /etc/passwd Change all file permission under directory: chown -R username:group directory Crontab \u00b6 Config crontab \u00b6 User level: crontab -e Global level: sudo nano /etc/crontab referr link Sample: */1 * * * * root /root/projects/anirec/start_anirec.sh Check crontab log \u00b6 centos sudo tail /var/log/cron ubuntu grep CRON /var/log/syslog","title":"Unix Commands & Bash"},{"location":"language/unix_commnads_bash/#unix-commands-bash","text":"","title":"Unix Commands &amp; Bash"},{"location":"language/unix_commnads_bash/#unix-commands","text":"","title":"Unix Commands"},{"location":"language/unix_commnads_bash/#samples","text":"Remove files under folder rm -rf /path/to/directory/* Count the number of files ls wc -l IP test curl ifconfig.me Search process by keyword ps -ef | grep {keyword} Search file by keyword ls {folder path} | grep {keyword} ls sort by size ls -ls -h -S Search log info by keyword cat {log file path} | grep {keyword}","title":"Samples"},{"location":"language/unix_commnads_bash/#libraries","text":"Memory view: atop Kill process by keyword: pkill -f supervisord","title":"Libraries"},{"location":"language/unix_commnads_bash/#referral","text":"Basic UNIX commands","title":"Referral"},{"location":"language/unix_commnads_bash/#bash","text":"Bash scripting cheatsheet","title":"Bash"},{"location":"language/unix_commnads_bash/#user-management","text":"","title":"User management"},{"location":"language/unix_commnads_bash/#referral_1","text":"Ubuntu File Permissions Ubuntu User Management","title":"Referral"},{"location":"language/unix_commnads_bash/#useful-commands","text":"Modify permission of file: chmod u+x filePath Add user to group: sudo adduser username groupname Check all user: cat /etc/passwd Change all file permission under directory: chown -R username:group directory","title":"Useful commands"},{"location":"language/unix_commnads_bash/#crontab","text":"","title":"Crontab"},{"location":"language/unix_commnads_bash/#config-crontab","text":"User level: crontab -e Global level: sudo nano /etc/crontab referr link Sample: */1 * * * * root /root/projects/anirec/start_anirec.sh","title":"Config crontab"},{"location":"language/unix_commnads_bash/#check-crontab-log","text":"centos sudo tail /var/log/cron ubuntu grep CRON /var/log/syslog","title":"Check crontab log"},{"location":"library/altair/","text":"Altair \u00b6 Sample import altair as alt import pandas as pd data = pd . DataFrame ({ 'x' : [ 'A' , 'B' , 'C' , 'D' , 'E' ], 'y' : [ 5 , 3 , 6 , 7 , 2 ]}) alt . Chart ( data ) . mark_bar () . encode ( x = 'x:O' , # specify ordinal data y = 'y:Q' , # specify quantitative data ) Altair\u2019s grammar works best with long-form data, in which each row corresponds to a single observation along with its metadata Encoding \u00b6 Encoding Encoding Channels: Position Channels: x,y,x2,y2 Mark Property Channels: color,fillopacity,size,shape Text and Tooltip Channels: text Hyperlink Channel: href Level of Detail Channel: detail Order Channel: order Facet Channels: column, row And some encoding can detailed defined by using options ,like: alt.X(\"xx\",aggregate=\"sum\") == x=\"sum(xx)\" alt.X(\"xx\",bin=True) Two gramma to define encoding: x=\"name:Q\" alt.X('name', type='quantitative') Support binning and aggregation like in database.For example alt . Chart ( cars ) . mark_point () . encode ( alt . X ( 'Horsepower' , bin = True ), alt . Y ( 'Miles_per_Gallon' , bin = True ), size = 'count()' , ) Different data properties will make color represent in different ways base = alt . Chart ( cars ) . mark_point () . encode ( x = 'Horsepower:Q' , y = 'Miles_per_Gallon:Q' , ) . properties ( width = 150 , height = 150 ) alt . vconcat ( base . encode ( color = 'Cylinders:Q' ) . properties ( title = 'quantitative' ), base . encode ( color = 'Cylinders:O' ) . properties ( title = 'ordinal' ), base . encode ( color = 'Cylinders:N' ) . properties ( title = 'nominal' ), ) mark \u00b6 Commonly used mark: mark_line mark_bar mark_circle mark_point mark_rect Mark supports add attributes. Interactive:Selection \u00b6 When selection is added to chart, alt.condition will make changes based on events Three type selection: alt.selection_interval alt.selection_single alt.selection_multi brush = alt . selection_interval ( encodings = [ 'x' ]) chart = alt . Chart ( cars ) . mark_point () . encode ( y = 'Horsepower:Q' , color = alt . condition ( brush , 'Origin:N' , alt . value ( 'lightgray' )) ) . properties ( width = 250 , height = 250 ) . add_selection ( brush ) Selection can set fields to make selection at legend of chart. selection = alt . selection_multi ( fields = [ 'Origin' ]) color = alt . condition ( selection , alt . Color ( 'Origin:N' , legend = None ), alt . value ( 'lightgray' )) scatter = alt . Chart ( cars ) . mark_point () . encode ( x = 'Horsepower:Q' , y = 'Miles_per_Gallon:Q' , color = color , tooltip = 'Name:N' ) legend = alt . Chart ( cars ) . mark_point () . encode ( y = alt . Y ( 'Origin:N' , axis = alt . Axis ( orient = 'right' )), color = color ) . add_selection ( selection ) scatter | legend Use bind to mark a form input selection = alt . selection_single ( fields = [ 'Origin' ], bind = input_dropdown , name = 'Country of ' ) # or slider = alt . binding_range ( min = 0 , max = 100 , step = 1 , name = 'cutoff:' ) selector = alt . selection_single ( name = \"SelectorName\" , fields = [ 'cutoff' ], bind = slider , init = { 'cutoff' : 50 }) Top-Level Chart Configuration \u00b6 doc Compound Charts \u00b6 Layer, HConcat, VConcat, Repeat, Facet For example chart . encode ( x = 'Acceleration:Q' ) | chart . encode ( x = 'Miles_per_Gallon:Q' ) Repeat can draw chart repeatly with some element different import altair as alt from vega_datasets import data iris = data . iris . url alt . Chart ( iris ) . mark_point () . encode ( alt . X ( alt . repeat ( \"column\" ), type = 'quantitative' ), alt . Y ( alt . repeat ( \"row\" ), type = 'quantitative' ), color = 'species:N' ) . properties ( width = 200 , height = 200 ) . repeat ( row = [ 'petalLength' , 'petalWidth' ], column = [ 'sepalLength' , 'sepalWidth' ] ) . interactive () Facet can draw chart divided by some class alt . Chart ( iris ) . mark_point () . encode ( x = 'petalLength:Q' , y = 'petalWidth:Q' , color = 'species:N' ) . properties ( width = 180 , height = 180 ) . facet ( column = 'species:N' ) Resolve scale can make compound Charts with different legend. alt . concat ( base . encode ( color = 'Origin:N' ), base . encode ( color = 'Cylinders:O' ) ) . resolve_scale ( color = 'independent' ) Save \u00b6 If you save the picture, you need to install selenium and browserdriver chart.save('chart.png') Json and html is also supported. Chart properties \u00b6 chart . properties ( width = 400 ) Multi-chart drawing \u00b6 alt.concat() and alt.vconcat()","title":"Altair"},{"location":"library/altair/#altair","text":"Sample import altair as alt import pandas as pd data = pd . DataFrame ({ 'x' : [ 'A' , 'B' , 'C' , 'D' , 'E' ], 'y' : [ 5 , 3 , 6 , 7 , 2 ]}) alt . Chart ( data ) . mark_bar () . encode ( x = 'x:O' , # specify ordinal data y = 'y:Q' , # specify quantitative data ) Altair\u2019s grammar works best with long-form data, in which each row corresponds to a single observation along with its metadata","title":"Altair"},{"location":"library/altair/#encoding","text":"Encoding Encoding Channels: Position Channels: x,y,x2,y2 Mark Property Channels: color,fillopacity,size,shape Text and Tooltip Channels: text Hyperlink Channel: href Level of Detail Channel: detail Order Channel: order Facet Channels: column, row And some encoding can detailed defined by using options ,like: alt.X(\"xx\",aggregate=\"sum\") == x=\"sum(xx)\" alt.X(\"xx\",bin=True) Two gramma to define encoding: x=\"name:Q\" alt.X('name', type='quantitative') Support binning and aggregation like in database.For example alt . Chart ( cars ) . mark_point () . encode ( alt . X ( 'Horsepower' , bin = True ), alt . Y ( 'Miles_per_Gallon' , bin = True ), size = 'count()' , ) Different data properties will make color represent in different ways base = alt . Chart ( cars ) . mark_point () . encode ( x = 'Horsepower:Q' , y = 'Miles_per_Gallon:Q' , ) . properties ( width = 150 , height = 150 ) alt . vconcat ( base . encode ( color = 'Cylinders:Q' ) . properties ( title = 'quantitative' ), base . encode ( color = 'Cylinders:O' ) . properties ( title = 'ordinal' ), base . encode ( color = 'Cylinders:N' ) . properties ( title = 'nominal' ), )","title":"Encoding"},{"location":"library/altair/#mark","text":"Commonly used mark: mark_line mark_bar mark_circle mark_point mark_rect Mark supports add attributes.","title":"mark"},{"location":"library/altair/#interactiveselection","text":"When selection is added to chart, alt.condition will make changes based on events Three type selection: alt.selection_interval alt.selection_single alt.selection_multi brush = alt . selection_interval ( encodings = [ 'x' ]) chart = alt . Chart ( cars ) . mark_point () . encode ( y = 'Horsepower:Q' , color = alt . condition ( brush , 'Origin:N' , alt . value ( 'lightgray' )) ) . properties ( width = 250 , height = 250 ) . add_selection ( brush ) Selection can set fields to make selection at legend of chart. selection = alt . selection_multi ( fields = [ 'Origin' ]) color = alt . condition ( selection , alt . Color ( 'Origin:N' , legend = None ), alt . value ( 'lightgray' )) scatter = alt . Chart ( cars ) . mark_point () . encode ( x = 'Horsepower:Q' , y = 'Miles_per_Gallon:Q' , color = color , tooltip = 'Name:N' ) legend = alt . Chart ( cars ) . mark_point () . encode ( y = alt . Y ( 'Origin:N' , axis = alt . Axis ( orient = 'right' )), color = color ) . add_selection ( selection ) scatter | legend Use bind to mark a form input selection = alt . selection_single ( fields = [ 'Origin' ], bind = input_dropdown , name = 'Country of ' ) # or slider = alt . binding_range ( min = 0 , max = 100 , step = 1 , name = 'cutoff:' ) selector = alt . selection_single ( name = \"SelectorName\" , fields = [ 'cutoff' ], bind = slider , init = { 'cutoff' : 50 })","title":"Interactive:Selection"},{"location":"library/altair/#top-level-chart-configuration","text":"doc","title":"Top-Level Chart Configuration"},{"location":"library/altair/#compound-charts","text":"Layer, HConcat, VConcat, Repeat, Facet For example chart . encode ( x = 'Acceleration:Q' ) | chart . encode ( x = 'Miles_per_Gallon:Q' ) Repeat can draw chart repeatly with some element different import altair as alt from vega_datasets import data iris = data . iris . url alt . Chart ( iris ) . mark_point () . encode ( alt . X ( alt . repeat ( \"column\" ), type = 'quantitative' ), alt . Y ( alt . repeat ( \"row\" ), type = 'quantitative' ), color = 'species:N' ) . properties ( width = 200 , height = 200 ) . repeat ( row = [ 'petalLength' , 'petalWidth' ], column = [ 'sepalLength' , 'sepalWidth' ] ) . interactive () Facet can draw chart divided by some class alt . Chart ( iris ) . mark_point () . encode ( x = 'petalLength:Q' , y = 'petalWidth:Q' , color = 'species:N' ) . properties ( width = 180 , height = 180 ) . facet ( column = 'species:N' ) Resolve scale can make compound Charts with different legend. alt . concat ( base . encode ( color = 'Origin:N' ), base . encode ( color = 'Cylinders:O' ) ) . resolve_scale ( color = 'independent' )","title":"Compound Charts"},{"location":"library/altair/#save","text":"If you save the picture, you need to install selenium and browserdriver chart.save('chart.png') Json and html is also supported.","title":"Save"},{"location":"library/altair/#chart-properties","text":"chart . properties ( width = 400 )","title":"Chart properties"},{"location":"library/altair/#multi-chart-drawing","text":"alt.concat() and alt.vconcat()","title":"Multi-chart drawing"},{"location":"library/numpy/","text":"Index \u00b6 Index Ndarray Matrix Random Tips Refferal Ndarray \u00b6 ndarray Build a ndarray np . array ( list ( \"12345\" ), dtype = \"int\" ) np . arange ( 15 ) . reshape (( 3 , 5 )) np . zeros (( 4 , 2 , 1 )) np . ones (( 4 , 2 , 1 )) np . empty (( 4 , 2 , 1 )) # linner space np . linspace ( start , stop , num ) # mesh grid np . meshgrid ( arr1 , arr2 ) # generate data from raw text np . genfromtxt ( StringIO ( data ), delimiter = \",\" ) Convert type arr.astyple(\"float\") Conver shape arr.flatten() arr.ravel() Combine array # combine by row np . vstack ([ arr1 , arr2 ]) # or np . r_ [ arr1 , arr2 ] # combine by col np . hstack ([ arr1 , arr2 ]) np . c_ [ arr1 , arr2 ] # combine with new level np . stack [ arr1 , arr2 ] # combine to one dimension np . append ( Arr1 , Arr2 ) Compare between ndarray np . in1d ( arr1 , arr2 ) union1d ( arr1 , arr2 ) setdiff1d ( arr1 , arr2 ) np . add ( arr1 , arr2 ) np . logical_and ( arr1 , arr2 ) np . dot ( arr1 , arr2 ) \u53d6\u552f\u4e00\u503c\uff1anp.unique(ints)\u7b49\u4ef7\u4e8e sorted\uff08set\uff08AA\uff09\uff09 \u9009\u53d6\u975e\u96f6\u5143\u7d20\u7684\u4f4d\u7f6e\uff0c\u53ef\u4ee5\u548c\u903b\u8f91\u5224\u65ad\u7ed3\u5408\u4f7f\u7528\uff1anp.nonzero(Arr) Matrix \u00b6 Ndarray as matrix # martix dot arr1 @ arr2 # or arr1.dot(arr2) Matrix # ndarray convert to matrix np.mat(arr) # matrix convert to ndarray mat.A # transpose arr.transpose(` # or arr.T # ${n}\\times{n}$ eye matrix np.eye(n) # inverse matrix mat.I Random \u00b6 Random number: # Evenly distributed float number in range [0,1] : np . random . rand ( d0 , d1 , ... , dn ) # Evenly distributed integer number: np . random . randint ( low , high = None , size = None ) # Binomial distribution: np . random . binomial ( n , p , size = None ) # Normal distribution: np . random . normal ( loc = 0.0 , scale = 1.0 , size = None ) # Standard normal distribution: np . random . randn ( d0 , d1 , ... , dn ) Others Choose one: choice(a, size=None, replace=True, p=None) Random permutation of sequences (without modifying objects): permutation(x) Random permutation of sequences (with modifying objects): shuffle(x) Random replacement sampling: [AA[x] for x in np.random.randint(0,3,10)] Generate random numbers with a sum of 1:$\\frac{number}{\\Sigma{number}}$ Generate random numbers between -1 and 1: rand([0,1])*2-1 Random control flow condition: `np.rand() > 0.6' Tips \u00b6 0 is represent row and 1 is column. when axis=0 row will be calculate and disappear.Axes is a plural form of axis. array can do $(n,m) \\times m$ ,but matrix can do $(n,m) \\times (m,k)$ Refferal \u00b6 Numpy 1.18 doc","title":"Numpy"},{"location":"library/numpy/#index","text":"Index Ndarray Matrix Random Tips Refferal","title":"Index"},{"location":"library/numpy/#ndarray","text":"ndarray Build a ndarray np . array ( list ( \"12345\" ), dtype = \"int\" ) np . arange ( 15 ) . reshape (( 3 , 5 )) np . zeros (( 4 , 2 , 1 )) np . ones (( 4 , 2 , 1 )) np . empty (( 4 , 2 , 1 )) # linner space np . linspace ( start , stop , num ) # mesh grid np . meshgrid ( arr1 , arr2 ) # generate data from raw text np . genfromtxt ( StringIO ( data ), delimiter = \",\" ) Convert type arr.astyple(\"float\") Conver shape arr.flatten() arr.ravel() Combine array # combine by row np . vstack ([ arr1 , arr2 ]) # or np . r_ [ arr1 , arr2 ] # combine by col np . hstack ([ arr1 , arr2 ]) np . c_ [ arr1 , arr2 ] # combine with new level np . stack [ arr1 , arr2 ] # combine to one dimension np . append ( Arr1 , Arr2 ) Compare between ndarray np . in1d ( arr1 , arr2 ) union1d ( arr1 , arr2 ) setdiff1d ( arr1 , arr2 ) np . add ( arr1 , arr2 ) np . logical_and ( arr1 , arr2 ) np . dot ( arr1 , arr2 ) \u53d6\u552f\u4e00\u503c\uff1anp.unique(ints)\u7b49\u4ef7\u4e8e sorted\uff08set\uff08AA\uff09\uff09 \u9009\u53d6\u975e\u96f6\u5143\u7d20\u7684\u4f4d\u7f6e\uff0c\u53ef\u4ee5\u548c\u903b\u8f91\u5224\u65ad\u7ed3\u5408\u4f7f\u7528\uff1anp.nonzero(Arr)","title":"Ndarray"},{"location":"library/numpy/#matrix","text":"Ndarray as matrix # martix dot arr1 @ arr2 # or arr1.dot(arr2) Matrix # ndarray convert to matrix np.mat(arr) # matrix convert to ndarray mat.A # transpose arr.transpose(` # or arr.T # ${n}\\times{n}$ eye matrix np.eye(n) # inverse matrix mat.I","title":"Matrix"},{"location":"library/numpy/#random","text":"Random number: # Evenly distributed float number in range [0,1] : np . random . rand ( d0 , d1 , ... , dn ) # Evenly distributed integer number: np . random . randint ( low , high = None , size = None ) # Binomial distribution: np . random . binomial ( n , p , size = None ) # Normal distribution: np . random . normal ( loc = 0.0 , scale = 1.0 , size = None ) # Standard normal distribution: np . random . randn ( d0 , d1 , ... , dn ) Others Choose one: choice(a, size=None, replace=True, p=None) Random permutation of sequences (without modifying objects): permutation(x) Random permutation of sequences (with modifying objects): shuffle(x) Random replacement sampling: [AA[x] for x in np.random.randint(0,3,10)] Generate random numbers with a sum of 1:$\\frac{number}{\\Sigma{number}}$ Generate random numbers between -1 and 1: rand([0,1])*2-1 Random control flow condition: `np.rand() > 0.6'","title":"Random"},{"location":"library/numpy/#tips","text":"0 is represent row and 1 is column. when axis=0 row will be calculate and disappear.Axes is a plural form of axis. array can do $(n,m) \\times m$ ,but matrix can do $(n,m) \\times (m,k)$","title":"Tips"},{"location":"library/numpy/#refferal","text":"Numpy 1.18 doc","title":"Refferal"},{"location":"library/others/","text":"xgboost \u00b6 from xgboost import XGBRegressor","title":"Others"},{"location":"library/others/#xgboost","text":"from xgboost import XGBRegressor","title":"xgboost"},{"location":"library/pandas/","text":"IO \u00b6 Series \u00b6 Create series pd . Series ( arr1 , index = arr2 ) # from dict pd . Series ( dictdata ) Data stucture pandas.series Tips \u00b6 Series can have duplicate keys Additions between series are automatically performed corresponding to the index. DataFrame \u00b6 Create dataframe pd . DataFrame ( arr , index = arr2 , columns = arr3 ) # from dict pd . DataFrame ( dicdata ) Combine Dataframe pd.concat([df1, df2],axis=1) Map and apply # map is only available on series df [ key ] . map ( callableObject ) # apply df [ key ] . apply ( callableObject ) Data discretization pd.cut Data structure DataFrame Aggregation \u00b6 Group by dataframe.groupby(key1) Data.groupby([key1, key2]) # Group by and select Data.groupby(key1)[key3] Agg dataframe . groupby ( key1 ) . agg ( func ) # suppot metirc: count\u3001sum\u3001mean\u3001median\u3001std\u3001var\u3001min\u3001max\u3001prod\u3001first\u3001last dataframe . groupby ( key1 ) . agg ([ fun1 , fun2 ]) Data . groupby ( key1 ) . agg ({ \"key2\" : func1 , \"key3\" :[ func2 , funct ]}) Missing value FF = lambda x \uff1a x . fillna ( x . mean ()) data . groupby ( \"AA\" ) . apply ( FF ) Stratified sampling def DD ( data , n = 5 ): return data . take ( np . random . permutation ( len ( Data ))[: n ]) dataframe . groupby [ \"AA\" ] . apply ( DD , n = 2 ) ``` ## Multi index ``` python # create index = pd . MultiIndex . from_tuples ( tuples , names = [ 'first' , 'second' ]) # index df . iloc [ df . index . get_level_values ( 'year' ) == 2020 ] # sort df . sortlevel ( level = 0 , axis = 1 ) Data reshape \u00b6 Referral Query Data \u00b6 Even thougth direct index is more easy to use, loc and iloc are officially recommended for production code. df = pd . DataFrame ( np . random . randn ( 30 , 4 ), columns = list ( \"abcd\" )) # loc df . loc [: 9 , [ \"a\" , \"b\" ]] # iloc df . iloc [: 10 , 0 : 2 ] # indexing operators f [: 10 ][[ \"a\" , \"b\" ]] # query df . query ( '(a < b) & (b < c)' ) Insert and Update \u00b6 Insert column # Use index df [ \"c\" ] = df [ \"a\" ] / df [ \"b\" ] # Use assign df . assign ( c = lambda x : x [ \"a\" ] * x [ \"b\" ]) Insert row # Append df . append ( df2 ) Update data # apply, apply function on current values df . apply ( np . sqrt ) df . apply ( np . sum , axis = 1 ) # where then replace df . where ( df < 0 , 0 ) # mask, mask() is the inverse boolean operation of where. df . mask ( df < 0 ) Combine, Split and reshape \u00b6 Combine \u00b6 # concat, use index as join on columns, not support for customize pd . concat ([ df1 , df2 ], axis = 0 ) # merge, can speciy pd . merge ( left , right , how = 'inner' , on = None , left_on = None , right_on = None , left_index = False , right_index = False , sort = True , suffixes = ( '_x' , '_y' ), copy = True , indicator = False , validate = None ) Split \u00b6 pd.cut() Reshape \u00b6 # Good for array compare pandas . crosstab # Good for dataframe columns compare pandas . pivot_table ( data , values = None , index = None , columns = None , aggfunc = 'mean' , fill_value = None , margins = False , dropna = True , margins_name = 'All' , observed = False ) \u2192 'DataFrame' # stack and unstack df . stack () # Melt, convert the other columns to two columns, one is column name and the other is value. df . melt ( id_vars = [ 'first' , 'last' ], var_name = 'new' ) Data analysis \u00b6 pd.get_dummies(series\uff0cprefix=\"\") Data type \u00b6 Get dataframe type info df . dtypes df . info () Missing Values == NA np . isnan pd . isnull Time series \u00b6 Create datetime pd.to_datetime(x) pd.date_range('2000-1-1', periods=1000, freq='M')\u6216\u8005 date_range(start, end,freq=Day) Timedelta Timedelta.days Auto group ts.resample(\"D\") ts.groupby(pd.TimeGrouper(freq=\"M\")) ts[someMonth] Shift ts.shift(3,freq=\"D\") Date + 3*Day()","title":"Pandas"},{"location":"library/pandas/#io","text":"","title":"IO"},{"location":"library/pandas/#series","text":"Create series pd . Series ( arr1 , index = arr2 ) # from dict pd . Series ( dictdata ) Data stucture pandas.series","title":"Series"},{"location":"library/pandas/#tips","text":"Series can have duplicate keys Additions between series are automatically performed corresponding to the index.","title":"Tips"},{"location":"library/pandas/#dataframe","text":"Create dataframe pd . DataFrame ( arr , index = arr2 , columns = arr3 ) # from dict pd . DataFrame ( dicdata ) Combine Dataframe pd.concat([df1, df2],axis=1) Map and apply # map is only available on series df [ key ] . map ( callableObject ) # apply df [ key ] . apply ( callableObject ) Data discretization pd.cut Data structure DataFrame","title":"DataFrame"},{"location":"library/pandas/#aggregation","text":"Group by dataframe.groupby(key1) Data.groupby([key1, key2]) # Group by and select Data.groupby(key1)[key3] Agg dataframe . groupby ( key1 ) . agg ( func ) # suppot metirc: count\u3001sum\u3001mean\u3001median\u3001std\u3001var\u3001min\u3001max\u3001prod\u3001first\u3001last dataframe . groupby ( key1 ) . agg ([ fun1 , fun2 ]) Data . groupby ( key1 ) . agg ({ \"key2\" : func1 , \"key3\" :[ func2 , funct ]}) Missing value FF = lambda x \uff1a x . fillna ( x . mean ()) data . groupby ( \"AA\" ) . apply ( FF ) Stratified sampling def DD ( data , n = 5 ): return data . take ( np . random . permutation ( len ( Data ))[: n ]) dataframe . groupby [ \"AA\" ] . apply ( DD , n = 2 ) ``` ## Multi index ``` python # create index = pd . MultiIndex . from_tuples ( tuples , names = [ 'first' , 'second' ]) # index df . iloc [ df . index . get_level_values ( 'year' ) == 2020 ] # sort df . sortlevel ( level = 0 , axis = 1 )","title":"Aggregation"},{"location":"library/pandas/#data-reshape","text":"Referral","title":"Data reshape"},{"location":"library/pandas/#query-data","text":"Even thougth direct index is more easy to use, loc and iloc are officially recommended for production code. df = pd . DataFrame ( np . random . randn ( 30 , 4 ), columns = list ( \"abcd\" )) # loc df . loc [: 9 , [ \"a\" , \"b\" ]] # iloc df . iloc [: 10 , 0 : 2 ] # indexing operators f [: 10 ][[ \"a\" , \"b\" ]] # query df . query ( '(a < b) & (b < c)' )","title":"Query Data"},{"location":"library/pandas/#insert-and-update","text":"Insert column # Use index df [ \"c\" ] = df [ \"a\" ] / df [ \"b\" ] # Use assign df . assign ( c = lambda x : x [ \"a\" ] * x [ \"b\" ]) Insert row # Append df . append ( df2 ) Update data # apply, apply function on current values df . apply ( np . sqrt ) df . apply ( np . sum , axis = 1 ) # where then replace df . where ( df < 0 , 0 ) # mask, mask() is the inverse boolean operation of where. df . mask ( df < 0 )","title":"Insert and Update"},{"location":"library/pandas/#combine-split-and-reshape","text":"","title":"Combine, Split and reshape"},{"location":"library/pandas/#combine","text":"# concat, use index as join on columns, not support for customize pd . concat ([ df1 , df2 ], axis = 0 ) # merge, can speciy pd . merge ( left , right , how = 'inner' , on = None , left_on = None , right_on = None , left_index = False , right_index = False , sort = True , suffixes = ( '_x' , '_y' ), copy = True , indicator = False , validate = None )","title":"Combine"},{"location":"library/pandas/#split","text":"pd.cut()","title":"Split"},{"location":"library/pandas/#reshape","text":"# Good for array compare pandas . crosstab # Good for dataframe columns compare pandas . pivot_table ( data , values = None , index = None , columns = None , aggfunc = 'mean' , fill_value = None , margins = False , dropna = True , margins_name = 'All' , observed = False ) \u2192 'DataFrame' # stack and unstack df . stack () # Melt, convert the other columns to two columns, one is column name and the other is value. df . melt ( id_vars = [ 'first' , 'last' ], var_name = 'new' )","title":"Reshape"},{"location":"library/pandas/#data-analysis","text":"pd.get_dummies(series\uff0cprefix=\"\")","title":"Data analysis"},{"location":"library/pandas/#data-type","text":"Get dataframe type info df . dtypes df . info () Missing Values == NA np . isnan pd . isnull","title":"Data type"},{"location":"library/pandas/#time-series","text":"Create datetime pd.to_datetime(x) pd.date_range('2000-1-1', periods=1000, freq='M')\u6216\u8005 date_range(start, end,freq=Day) Timedelta Timedelta.days Auto group ts.resample(\"D\") ts.groupby(pd.TimeGrouper(freq=\"M\")) ts[someMonth] Shift ts.shift(3,freq=\"D\") Date + 3*Day()","title":"Time series"},{"location":"library/pytest/","text":"Pytest \u00b6 command \u00b6 Show output info and allow debug mode: pytest -s Test single function\uff1a pytest test_mod.py::test_func mark \u00b6 use mark: @pytest . mark . pyfile def test_something (): pass Test marked tests: pytest -m pyfile mock \u00b6 Base on pytest-mock from pytest_mock import mocker def test_func ( mocker ): # mocker.patch # mocker.patch.object object . method . return_value = [] Assert is called once: isfile.assert_called_once() Replace return value: isfile.return_value = False Exception catch \u00b6 with pytest.raises(ZeroDivisionError): 1 / 0 Fixture \u00b6 Use decorator to set a fixture, then send this function as a parameter to another function @pytest . fixture def fixture_func (): pass def test_func ( fixture_func ): pass Use closure to send parameter to fixture @pytest . fixture def make_customer_record (): def _make_customer_record ( name ): return { \"name\" : name , \"orders\" : [] } return _make_customer_record def test_customer_records ( make_customer_record ): customer_1 = make_customer_record ( \"Lisa\" ) customer_2 = make_customer_record ( \"Mike\" ) customer_3 = make_customer_record ( \"Meredith\" ) Performance \u00b6 Watch duration: pytest --durations=0 Profile function runtime: pip in stall pytest-profiling Config in pytest.ini pytest_plugins = ['pytest_profiling'] Pytest --profile Isolate long test use @pytest.mark.long to mark function pytest -m \"not long\" Attetion \u00b6 Test for-loop: Pay attention to test the number of data first to avoid passing by empty data.","title":"Pytest"},{"location":"library/pytest/#pytest","text":"","title":"Pytest"},{"location":"library/pytest/#command","text":"Show output info and allow debug mode: pytest -s Test single function\uff1a pytest test_mod.py::test_func","title":"command"},{"location":"library/pytest/#mark","text":"use mark: @pytest . mark . pyfile def test_something (): pass Test marked tests: pytest -m pyfile","title":"mark"},{"location":"library/pytest/#mock","text":"Base on pytest-mock from pytest_mock import mocker def test_func ( mocker ): # mocker.patch # mocker.patch.object object . method . return_value = [] Assert is called once: isfile.assert_called_once() Replace return value: isfile.return_value = False","title":"mock"},{"location":"library/pytest/#exception-catch","text":"with pytest.raises(ZeroDivisionError): 1 / 0","title":"Exception catch"},{"location":"library/pytest/#fixture","text":"Use decorator to set a fixture, then send this function as a parameter to another function @pytest . fixture def fixture_func (): pass def test_func ( fixture_func ): pass Use closure to send parameter to fixture @pytest . fixture def make_customer_record (): def _make_customer_record ( name ): return { \"name\" : name , \"orders\" : [] } return _make_customer_record def test_customer_records ( make_customer_record ): customer_1 = make_customer_record ( \"Lisa\" ) customer_2 = make_customer_record ( \"Mike\" ) customer_3 = make_customer_record ( \"Meredith\" )","title":"Fixture"},{"location":"library/pytest/#performance","text":"Watch duration: pytest --durations=0 Profile function runtime: pip in stall pytest-profiling Config in pytest.ini pytest_plugins = ['pytest_profiling'] Pytest --profile Isolate long test use @pytest.mark.long to mark function pytest -m \"not long\"","title":"Performance"},{"location":"library/pytest/#attetion","text":"Test for-loop: Pay attention to test the number of data first to avoid passing by empty data.","title":"Attetion"},{"location":"library/sklearn/","text":"Dataset transformations \u00b6 Pipelines and composite estimators \u00b6 Use pipeline to combine multiple transformer and estimator.Step and parameter can be set use set_params method.If cache is need, can set with memory=cachedir import tempfile from sklearn.pipeline import Pipeline cachefile = tempfile . mktemp () pipe = Pipeline ( [ ( \"std\" , preprocessing . StandardScaler ()), ( \"model\" , RandomForestRegressor ()) ], memory = cachefile ) pipe . set_params ( std = 'passthrough' , model__min_samples_split = 10 ) pipe . fit ( xr , yr ) pipe . predict ( xt ) FeatureUnion combines several transformer objects into a new transformer that combines their output. ColumnTransformer helps performing different transformations for different columns of the data. from sklearn.compose import ColumnTransformer df = pd . DataFrame ( X , columns = feature_names ) columnsTrans = ColumnTransformer ( [ ( \"std\" , StandardScaler (), [ \"alcohol\" ]), ( \"quant\" , QuantileTransformer ( n_quantiles = 100 ), [ \"malic_acid\" ]), ], remainder = \"passthrough\" , ) result = columnsTrans . fit_transform ( df ) Feature extraction \u00b6 Import from sklearn.feature_extraction import DictVectorizer from sklearn.feature_extraction.text import CountVectorizer from sklearn.feature_extraction import image Sklearn has some useful implement in NLP. Preprocessing data \u00b6 Import from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import QuantileTransformer from sklearn.preprocessing import PowerTransformer from sklearn.preprocessing import Normalizer from sklearn.preprocessing import OrdinalEncoder from sklearn.preprocessing import OneHotEncoder from sklearn.preprocessing import KBinsDiscretizer from sklearn.preprocessing import Binarizer from sklearn.preprocessing import PolynomialFeatures from sklearn.preprocessing import FunctionTransformer Imputation of missing values \u00b6 Simple inputer with many strategy:'mean','median', 'most_frequent', 'constant' from sklearn.impute import SimpleImputer imp = SimpleImputer ( missing_values = np . nan , strategy = 'mean' ) imp . fit ( X1 ) imp . transform ( X2 ) Unsupervised dimensionality reduction \u00b6 Imports from sklearn.decomposition import PCA from sklearn.cluster import FeatureAgglomeration Pairwise metrics, Affinities and Kernels \u00b6 Pairwise metrics import numpy as np from sklearn.metrics import pairwise_distances from sklearn.metrics.pairwise import pairwise_kernels X = np . array ([[ 2 , 3 ], [ 3 , 5 ], [ 5 , 8 ]]) Y = np . array ([[ 1 , 0 ], [ 2 , 1 ]]) pairwise_distances ( X , Y , metric = 'manhattan' ) pairwise_distances ( X , metric = 'manhattan' ) Models \u00b6 Import models from sklearn.linear_model import LinearRegression from sklearn.linear_model import LogisticRegression from sklearn.tree import DecisionTreeClassifier from sklearn.tree import DecisionTreeRegressor from sklearn.naive_bayes import GaussianNB from sklearn.ensemble import RandomForestClassifier Feature selection \u00b6 from sklearn import feature_selection fs = feature_selection . SelectPercentile ( feature_selection . chi2 , percentile = 25 ) fs . fit ( X , y ) fs . get_support () fs . transform ( X ) Selectors: SelectPercentile SelectKBest RFECV: feature_selection.RFECV(estimator=classifier,step=1,cv=10,scoring='accuracy') Model selection \u00b6 Cross-validation from sklearn.model_selection import cross_val_score scores = cross_val_score ( clf , X , y , cv = 5 , scoring = 'f1_macro' ) print ( \"Score: %0.2f (+/- %0.2f )\" % ( scores . mean (), scores . std () * 2 )) Cross-valid wiht multiple metrics and detailed result. from sklearn.model_selection import cross_validate scores = cross_validate ( clf , X , y , scoring = scoring ) Iterators which can be set in cv parameter in Cross validation.If there are groups in sample which need to place at some set, can set groups parameter in iterrators. from sklearn.model_selection import KFold from sklearn.model_selection import RepeatedKFold from sklearn.model_selection import LeaveOneOut from sklearn.model_selection import StratifiedKFold from sklearn.model_selection import TimeSeriesSplit Gridsearch from sklearn.model_selection import GridSearchCV parameters = { 'para1' :( \"a\" , \"b\" ), 'para2' :[ 1 , 2 ]} clf = GridSearchCV ( clf , parameters ) clf . fit ( X , y ) sorted ( clf . cv_results_ ) Scoreing metircs.Dummy estimators are useful to get a baseline value of those metrics for random predictions.Common score metrics: # for classify metrics . accuracy_score metrics . balanced_accuracy_score metrics . f1_score metrics . precision_score metrics . recall_score metrics . roc_auc_score # fot cluster metrics . adjusted_mutual_info_score # for regression metrics . mean_squared_error metrics . r2_score metrics . explained_variance_score Use learning to compare sample size vs scores from sklearn.model_selection import validation_curve from sklearn.model_selection import learning_curve Referral \u00b6 Sklearn User guide","title":"Sklearn"},{"location":"library/sklearn/#dataset-transformations","text":"","title":"Dataset transformations"},{"location":"library/sklearn/#pipelines-and-composite-estimators","text":"Use pipeline to combine multiple transformer and estimator.Step and parameter can be set use set_params method.If cache is need, can set with memory=cachedir import tempfile from sklearn.pipeline import Pipeline cachefile = tempfile . mktemp () pipe = Pipeline ( [ ( \"std\" , preprocessing . StandardScaler ()), ( \"model\" , RandomForestRegressor ()) ], memory = cachefile ) pipe . set_params ( std = 'passthrough' , model__min_samples_split = 10 ) pipe . fit ( xr , yr ) pipe . predict ( xt ) FeatureUnion combines several transformer objects into a new transformer that combines their output. ColumnTransformer helps performing different transformations for different columns of the data. from sklearn.compose import ColumnTransformer df = pd . DataFrame ( X , columns = feature_names ) columnsTrans = ColumnTransformer ( [ ( \"std\" , StandardScaler (), [ \"alcohol\" ]), ( \"quant\" , QuantileTransformer ( n_quantiles = 100 ), [ \"malic_acid\" ]), ], remainder = \"passthrough\" , ) result = columnsTrans . fit_transform ( df )","title":"Pipelines and composite estimators"},{"location":"library/sklearn/#feature-extraction","text":"Import from sklearn.feature_extraction import DictVectorizer from sklearn.feature_extraction.text import CountVectorizer from sklearn.feature_extraction import image Sklearn has some useful implement in NLP.","title":"Feature extraction"},{"location":"library/sklearn/#preprocessing-data","text":"Import from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import QuantileTransformer from sklearn.preprocessing import PowerTransformer from sklearn.preprocessing import Normalizer from sklearn.preprocessing import OrdinalEncoder from sklearn.preprocessing import OneHotEncoder from sklearn.preprocessing import KBinsDiscretizer from sklearn.preprocessing import Binarizer from sklearn.preprocessing import PolynomialFeatures from sklearn.preprocessing import FunctionTransformer","title":"Preprocessing data"},{"location":"library/sklearn/#imputation-of-missing-values","text":"Simple inputer with many strategy:'mean','median', 'most_frequent', 'constant' from sklearn.impute import SimpleImputer imp = SimpleImputer ( missing_values = np . nan , strategy = 'mean' ) imp . fit ( X1 ) imp . transform ( X2 )","title":"Imputation of missing values"},{"location":"library/sklearn/#unsupervised-dimensionality-reduction","text":"Imports from sklearn.decomposition import PCA from sklearn.cluster import FeatureAgglomeration","title":"Unsupervised dimensionality reduction"},{"location":"library/sklearn/#pairwise-metrics-affinities-and-kernels","text":"Pairwise metrics import numpy as np from sklearn.metrics import pairwise_distances from sklearn.metrics.pairwise import pairwise_kernels X = np . array ([[ 2 , 3 ], [ 3 , 5 ], [ 5 , 8 ]]) Y = np . array ([[ 1 , 0 ], [ 2 , 1 ]]) pairwise_distances ( X , Y , metric = 'manhattan' ) pairwise_distances ( X , metric = 'manhattan' )","title":"Pairwise metrics, Affinities and Kernels"},{"location":"library/sklearn/#models","text":"Import models from sklearn.linear_model import LinearRegression from sklearn.linear_model import LogisticRegression from sklearn.tree import DecisionTreeClassifier from sklearn.tree import DecisionTreeRegressor from sklearn.naive_bayes import GaussianNB from sklearn.ensemble import RandomForestClassifier","title":"Models"},{"location":"library/sklearn/#feature-selection","text":"from sklearn import feature_selection fs = feature_selection . SelectPercentile ( feature_selection . chi2 , percentile = 25 ) fs . fit ( X , y ) fs . get_support () fs . transform ( X ) Selectors: SelectPercentile SelectKBest RFECV: feature_selection.RFECV(estimator=classifier,step=1,cv=10,scoring='accuracy')","title":"Feature selection"},{"location":"library/sklearn/#model-selection","text":"Cross-validation from sklearn.model_selection import cross_val_score scores = cross_val_score ( clf , X , y , cv = 5 , scoring = 'f1_macro' ) print ( \"Score: %0.2f (+/- %0.2f )\" % ( scores . mean (), scores . std () * 2 )) Cross-valid wiht multiple metrics and detailed result. from sklearn.model_selection import cross_validate scores = cross_validate ( clf , X , y , scoring = scoring ) Iterators which can be set in cv parameter in Cross validation.If there are groups in sample which need to place at some set, can set groups parameter in iterrators. from sklearn.model_selection import KFold from sklearn.model_selection import RepeatedKFold from sklearn.model_selection import LeaveOneOut from sklearn.model_selection import StratifiedKFold from sklearn.model_selection import TimeSeriesSplit Gridsearch from sklearn.model_selection import GridSearchCV parameters = { 'para1' :( \"a\" , \"b\" ), 'para2' :[ 1 , 2 ]} clf = GridSearchCV ( clf , parameters ) clf . fit ( X , y ) sorted ( clf . cv_results_ ) Scoreing metircs.Dummy estimators are useful to get a baseline value of those metrics for random predictions.Common score metrics: # for classify metrics . accuracy_score metrics . balanced_accuracy_score metrics . f1_score metrics . precision_score metrics . recall_score metrics . roc_auc_score # fot cluster metrics . adjusted_mutual_info_score # for regression metrics . mean_squared_error metrics . r2_score metrics . explained_variance_score Use learning to compare sample size vs scores from sklearn.model_selection import validation_curve from sklearn.model_selection import learning_curve","title":"Model selection"},{"location":"library/sklearn/#referral","text":"Sklearn User guide","title":"Referral"},{"location":"server/airflow/","text":"Airflow \u00b6 Install \u00b6 pip install apache-airflow Admin \u00b6 Start \u00b6 airflow webserver airflow scheduler Add new dag \u00b6 Create a DAG definition script under \"{AIRFLOW_HOME}/dags/\" Import Airflow: import airflow Set default_args Init DAG Create Task include or inherit the arguments task_id and owner (Optionally) use Jinja template create a flexible command in task Setting up Dependencies between tasks, reuslt in a DAG (Optionally) Testing Test static syntax: python {dag script filepath} Metadata Validation\uff1a airflow list_dags and airflow list_tasks {task name} Test special task: airflow test {dag name} {task name} {date, like 2015-06-01} (Optionally) Backfill\uff1a airflow backfill {dag name} -s {startDate, like 2015-06-01} -e {endDate, like 2015-06-07} (Optionally)Init Database: airflow initdb Debug \u00b6 No module named 'werkzeug.wrappers.json' \u00b6 pip install -U Flask==1.0.4 Referral \u00b6 Airflow Official Site","title":"Airflow"},{"location":"server/airflow/#airflow","text":"","title":"Airflow"},{"location":"server/airflow/#install","text":"pip install apache-airflow","title":"Install"},{"location":"server/airflow/#admin","text":"","title":"Admin"},{"location":"server/airflow/#start","text":"airflow webserver airflow scheduler","title":"Start"},{"location":"server/airflow/#add-new-dag","text":"Create a DAG definition script under \"{AIRFLOW_HOME}/dags/\" Import Airflow: import airflow Set default_args Init DAG Create Task include or inherit the arguments task_id and owner (Optionally) use Jinja template create a flexible command in task Setting up Dependencies between tasks, reuslt in a DAG (Optionally) Testing Test static syntax: python {dag script filepath} Metadata Validation\uff1a airflow list_dags and airflow list_tasks {task name} Test special task: airflow test {dag name} {task name} {date, like 2015-06-01} (Optionally) Backfill\uff1a airflow backfill {dag name} -s {startDate, like 2015-06-01} -e {endDate, like 2015-06-07} (Optionally)Init Database: airflow initdb","title":"Add new dag"},{"location":"server/airflow/#debug","text":"","title":"Debug"},{"location":"server/airflow/#no-module-named-werkzeugwrappersjson","text":"pip install -U Flask==1.0.4","title":"No module named 'werkzeug.wrappers.json'"},{"location":"server/airflow/#referral","text":"Airflow Official Site","title":"Referral"},{"location":"server/django/","text":"Django \u00b6 Install \u00b6 pip install django Admin \u00b6 Start new project \u00b6 django-admin startproject {site name} Start new app \u00b6 Create new app folder: python manage.py startapp {app name} {app path} Add app to setting.py : setting.installed_apps Create Model in models.py from django.db import models class User(models.Model): name = models.CharField(max_length=50, default=\"admin\") email = models.EmailField(max_length=50) Create view in views.py from django.http import JsonResponse, HttpResponse def hello(request): return HttpResponse(\"Hello\") Add route in urls.py from django.urls import path from newapp import views urlpatterns = [ path('newapp', views.hello), ] Add urls in global urls.py : from django.conf.urls import include, url urlpatterns = [ path('newapp', include('newapp.urls')), ] (Optionally) Add model to admin in admin.py from django.contrib import admin from newpp.models import User @admin.register(User) def UserAdmin(admin.ModelAdmin): pass Finished Change admin password \u00b6 python manage.py changepassword <user_name> Two different ways to add url \u00b6 Use include from django.conf.urls import include , url urlpatterns = [ path ( 'newapp' , include ( 'newapp.urls' )), ] Import module from django.conf.urls import include , url import newapp urlpatterns = [ path ( 'newapp' , newapp . urls ), ] Frequently used moudles \u00b6 Moduel Useage Sample django.db build model from django.db import models django.http build response from django.http import JsonResponse django.urls build route from django.urls import path django.core core modules from django.core import serializers django.contrib addon modules from django.contrib import admin django.shortcuts Convenient shortcut from django.shortcuts import render django.utils common tools from django.utils import timezone django.conf get django config from django.conf import settings django.apps get django app config from django.apps import AppConfig django.test build test from django.test import TestCase Models \u00b6 Init model \u00b6 Question(question_text=\"What's new?\",pub_date=timezone.now()) Query model \u00b6 Question.objects.get(pk=1) Question.objects.all() Question.objects.filter() Question.objects.raw({SQL}) Debugging model \u00b6 python manage.py shell Views \u00b6 Build response \u00b6 Html from django.shortcuts import render def hello ( request ) return render ( request , '{html page path}' , { data }) Json from django.http import HttpResponse def hello ( request ) return JsonResponse ({ data }) Others from django.http import HttpResponse def hello ( request ) return HttpResponse ( status = 201 ) Get request content \u00b6 GET: request.GET.dict() POST: request.POST.dict() PUT: from django.http import QueryDict;QueryDict(request.body) PATCH: same with put DELETE: same with put Test \u00b6 Build test script from django.test import TestCase class Test1(TestCase): def test_get(): result = self.client.get('user') Run test python manage.py test newapp","title":"Django"},{"location":"server/django/#django","text":"","title":"Django"},{"location":"server/django/#install","text":"pip install django","title":"Install"},{"location":"server/django/#admin","text":"","title":"Admin"},{"location":"server/django/#start-new-project","text":"django-admin startproject {site name}","title":"Start new project"},{"location":"server/django/#start-new-app","text":"Create new app folder: python manage.py startapp {app name} {app path} Add app to setting.py : setting.installed_apps Create Model in models.py from django.db import models class User(models.Model): name = models.CharField(max_length=50, default=\"admin\") email = models.EmailField(max_length=50) Create view in views.py from django.http import JsonResponse, HttpResponse def hello(request): return HttpResponse(\"Hello\") Add route in urls.py from django.urls import path from newapp import views urlpatterns = [ path('newapp', views.hello), ] Add urls in global urls.py : from django.conf.urls import include, url urlpatterns = [ path('newapp', include('newapp.urls')), ] (Optionally) Add model to admin in admin.py from django.contrib import admin from newpp.models import User @admin.register(User) def UserAdmin(admin.ModelAdmin): pass Finished","title":"Start new app"},{"location":"server/django/#change-admin-password","text":"python manage.py changepassword <user_name>","title":"Change admin password"},{"location":"server/django/#two-different-ways-to-add-url","text":"Use include from django.conf.urls import include , url urlpatterns = [ path ( 'newapp' , include ( 'newapp.urls' )), ] Import module from django.conf.urls import include , url import newapp urlpatterns = [ path ( 'newapp' , newapp . urls ), ]","title":"Two different ways to add url"},{"location":"server/django/#frequently-used-moudles","text":"Moduel Useage Sample django.db build model from django.db import models django.http build response from django.http import JsonResponse django.urls build route from django.urls import path django.core core modules from django.core import serializers django.contrib addon modules from django.contrib import admin django.shortcuts Convenient shortcut from django.shortcuts import render django.utils common tools from django.utils import timezone django.conf get django config from django.conf import settings django.apps get django app config from django.apps import AppConfig django.test build test from django.test import TestCase","title":"Frequently used moudles"},{"location":"server/django/#models","text":"","title":"Models"},{"location":"server/django/#init-model","text":"Question(question_text=\"What's new?\",pub_date=timezone.now())","title":"Init model"},{"location":"server/django/#query-model","text":"Question.objects.get(pk=1) Question.objects.all() Question.objects.filter() Question.objects.raw({SQL})","title":"Query model"},{"location":"server/django/#debugging-model","text":"python manage.py shell","title":"Debugging model"},{"location":"server/django/#views","text":"","title":"Views"},{"location":"server/django/#build-response","text":"Html from django.shortcuts import render def hello ( request ) return render ( request , '{html page path}' , { data }) Json from django.http import HttpResponse def hello ( request ) return JsonResponse ({ data }) Others from django.http import HttpResponse def hello ( request ) return HttpResponse ( status = 201 )","title":"Build response"},{"location":"server/django/#get-request-content","text":"GET: request.GET.dict() POST: request.POST.dict() PUT: from django.http import QueryDict;QueryDict(request.body) PATCH: same with put DELETE: same with put","title":"Get request content"},{"location":"server/django/#test","text":"Build test script from django.test import TestCase class Test1(TestCase): def test_get(): result = self.client.get('user') Run test python manage.py test newapp","title":"Test"},{"location":"server/flask/","text":"Flask \u00b6 Official Doc Start app \u00b6 from flask import Flask app = Flask ( __name__ ) @app . route ( \"/\" ) def home (): return \"Hello FLask\" app . run ( host = '0.0.0.0' , port = 5000 , debug = True ) Often imported modules from flask import ( flash , g , redirect , render_template , request , session , url_for ) Route \u00b6 Methods: GET, POST, PUT, DELETE, HEAD, OPTIONS @app . route ( '/login' , methods = [ 'GET' , 'POST' ]) general router: @app.route(url) before general router: @app.before_request after general router: @app.after_request before reuqest finished: @app.teardown_request Response types: page: render_template('index.html') redirect: redirect('/') information: flash(\u201cxxx\u201d) error: abort(404) Route with paramter @app . route ( 'user/<name>' ) def user ( name ): return '<h1>hello, %s !</h1>' % name Test \u00b6 import pytest from flaskr import views @pytest . fixture def client (): views . app . config [ 'TESTING' ] = True client = views . app . test_client () yield client def test_empty_db ( client ): rv = client . get ( '/' ) assert rv . status_code in 00","title":"Flask"},{"location":"server/flask/#flask","text":"Official Doc","title":"Flask"},{"location":"server/flask/#start-app","text":"from flask import Flask app = Flask ( __name__ ) @app . route ( \"/\" ) def home (): return \"Hello FLask\" app . run ( host = '0.0.0.0' , port = 5000 , debug = True ) Often imported modules from flask import ( flash , g , redirect , render_template , request , session , url_for )","title":"Start app"},{"location":"server/flask/#route","text":"Methods: GET, POST, PUT, DELETE, HEAD, OPTIONS @app . route ( '/login' , methods = [ 'GET' , 'POST' ]) general router: @app.route(url) before general router: @app.before_request after general router: @app.after_request before reuqest finished: @app.teardown_request Response types: page: render_template('index.html') redirect: redirect('/') information: flash(\u201cxxx\u201d) error: abort(404) Route with paramter @app . route ( 'user/<name>' ) def user ( name ): return '<h1>hello, %s !</h1>' % name","title":"Route"},{"location":"server/flask/#test","text":"import pytest from flaskr import views @pytest . fixture def client (): views . app . config [ 'TESTING' ] = True client = views . app . test_client () yield client def test_empty_db ( client ): rv = client . get ( '/' ) assert rv . status_code in 00","title":"Test"},{"location":"server/jekyll/","text":"Jekyll \u00b6 Admin \u00b6 Build: jekyll build Server: jekyll serve --- layout: default title: About --- # About page This page tells you a little bit about me. Tips \u00b6 Jekyll use Liquid as a templating language. Use Front Matter to set page variables. A layout html can be reused in many pages by Front Matter Url route can be included in one file. Jekyll supports loading data from YAML, JSON, and CSV files located in a data directory. Deploy \u00b6 Official Doc Push to gitbub master branch Debug \u00b6 Slow setup \u00b6 Change source bundle config '[https://ruby.taobao.org](https://ruby.taobao.org/)' '[https://gems.ruby-china.com/](https://gems.ruby-china.com/)'","title":"Jekyll"},{"location":"server/jekyll/#jekyll","text":"","title":"Jekyll"},{"location":"server/jekyll/#admin","text":"Build: jekyll build Server: jekyll serve --- layout: default title: About --- # About page This page tells you a little bit about me.","title":"Admin"},{"location":"server/jekyll/#tips","text":"Jekyll use Liquid as a templating language. Use Front Matter to set page variables. A layout html can be reused in many pages by Front Matter Url route can be included in one file. Jekyll supports loading data from YAML, JSON, and CSV files located in a data directory.","title":"Tips"},{"location":"server/jekyll/#deploy","text":"Official Doc Push to gitbub master branch","title":"Deploy"},{"location":"server/jekyll/#debug","text":"","title":"Debug"},{"location":"server/jekyll/#slow-setup","text":"Change source bundle config '[https://ruby.taobao.org](https://ruby.taobao.org/)' '[https://gems.ruby-china.com/](https://gems.ruby-china.com/)'","title":"Slow setup"},{"location":"server/mkdocs/","text":"Mkdocs \u00b6 mkdocs mkdocs-material","title":"Mkdocs"},{"location":"server/mkdocs/#mkdocs","text":"mkdocs mkdocs-material","title":"Mkdocs"},{"location":"server/mongo/","text":"Mongo \u00b6 Query \u00b6 How to select collection \u00b6 { database }.{ collection }. find () Query, filter and limit \u00b6 db . inventory . find ({ status : \"A\" }, { item : 1 , status : 1 }). limit ( 10 ); filter is write before select columns Aggregate \u00b6 db . orders . aggregate ([ { $match : { status : \"A\" } }, { $group : { _id : \"$cust_id\" , total : { $sum : \"$amount\" } } } ]); like a pipeline , combined in a list Commonly used pipeline element: \u00b6 match: { $match : { status : \"A\" ; } } group: { $group : { _id : \"$cust_id\" , total : { $sum : \"$amount\" } } } unwind: { $unwind : \"$history\" ; } lookup: { $lookup : { from : \"anime_info\" , localField : \"history.id\" , foreignField : \"id\" , as : \"anime\" } } project: { $project : { _id : 0 , id : \"$history.id\" , title_japanese : { $ifNull : [ \"$anime.title.native\" , \"$anime.title.romaji\" ] }, title_romaji : \"$anime.title.romaji\" , start_date_fuzzy : \"$anime.startDateFuzzy\" , popularity : \"$anime.popularity\" , image_url_lge : \"$anime.coverImage.large\" , image_url_med : \"$anime.coverImage.large\" , genres : \"$anime.genres\" , total_episodes : \"$anime.episodes\" , isviewed : \"\\$history.view_status\" , description : \"\" } } skip and limit { $skip : 0 }, { $limit : 10 } Official Quick Reference Admin \u00b6 Install \u00b6 Ubuntu: Official doc Shell commands \u00b6 mongo: runtime manage command mongod: service start, restart and stop command start mongo: sudo service mongod start mongo commands \u00b6 show dbs use {dbname} db.collection db.collection.find db.collection.insert security \u00b6 Role is different from user.One user can have mutiple roles.Role is first, then users. Modify user role: db . grantRolesToUser ( \"admin\" , [{ role : \"root\" , db : \"admin\" }]); Migrate \u00b6 dump mongodump --uri \"mongodb://{username}:{password}@{host}:{port}\" --out { filepath } store mongorestore --host { host } --port { port } --username { username } --password { password } --db { dbname } { filepath } Debug \u00b6 log file location: /var/log/mongodb/mongod.log Auth Error \u00b6 detail: error getting auth version of server: not authorized on admin to execute command solution: statckoverflow","title":"Mongo"},{"location":"server/mongo/#mongo","text":"","title":"Mongo"},{"location":"server/mongo/#query","text":"","title":"Query"},{"location":"server/mongo/#how-to-select-collection","text":"{ database }.{ collection }. find ()","title":"How to select collection"},{"location":"server/mongo/#query-filter-and-limit","text":"db . inventory . find ({ status : \"A\" }, { item : 1 , status : 1 }). limit ( 10 ); filter is write before select columns","title":"Query, filter and limit"},{"location":"server/mongo/#aggregate","text":"db . orders . aggregate ([ { $match : { status : \"A\" } }, { $group : { _id : \"$cust_id\" , total : { $sum : \"$amount\" } } } ]); like a pipeline , combined in a list","title":"Aggregate"},{"location":"server/mongo/#commonly-used-pipeline-element","text":"match: { $match : { status : \"A\" ; } } group: { $group : { _id : \"$cust_id\" , total : { $sum : \"$amount\" } } } unwind: { $unwind : \"$history\" ; } lookup: { $lookup : { from : \"anime_info\" , localField : \"history.id\" , foreignField : \"id\" , as : \"anime\" } } project: { $project : { _id : 0 , id : \"$history.id\" , title_japanese : { $ifNull : [ \"$anime.title.native\" , \"$anime.title.romaji\" ] }, title_romaji : \"$anime.title.romaji\" , start_date_fuzzy : \"$anime.startDateFuzzy\" , popularity : \"$anime.popularity\" , image_url_lge : \"$anime.coverImage.large\" , image_url_med : \"$anime.coverImage.large\" , genres : \"$anime.genres\" , total_episodes : \"$anime.episodes\" , isviewed : \"\\$history.view_status\" , description : \"\" } } skip and limit { $skip : 0 }, { $limit : 10 } Official Quick Reference","title":"Commonly used pipeline element:"},{"location":"server/mongo/#admin","text":"","title":"Admin"},{"location":"server/mongo/#install","text":"Ubuntu: Official doc","title":"Install"},{"location":"server/mongo/#shell-commands","text":"mongo: runtime manage command mongod: service start, restart and stop command start mongo: sudo service mongod start","title":"Shell commands"},{"location":"server/mongo/#mongo-commands","text":"show dbs use {dbname} db.collection db.collection.find db.collection.insert","title":"mongo commands"},{"location":"server/mongo/#security","text":"Role is different from user.One user can have mutiple roles.Role is first, then users. Modify user role: db . grantRolesToUser ( \"admin\" , [{ role : \"root\" , db : \"admin\" }]);","title":"security"},{"location":"server/mongo/#migrate","text":"dump mongodump --uri \"mongodb://{username}:{password}@{host}:{port}\" --out { filepath } store mongorestore --host { host } --port { port } --username { username } --password { password } --db { dbname } { filepath }","title":"Migrate"},{"location":"server/mongo/#debug","text":"log file location: /var/log/mongodb/mongod.log","title":"Debug"},{"location":"server/mongo/#auth-error","text":"detail: error getting auth version of server: not authorized on admin to execute command solution: statckoverflow","title":"Auth Error"},{"location":"server/nginx/","text":"Nginx \u00b6 Install \u00b6 Install on Ubuntu sudo apt-get update sudo apt-get install nginx Version check nginx -v Admin \u00b6 Start server \u00b6 sudo /etc/init.d/nginx start # or sudo /usr/local/nginx/sbin/nginx # or sudo service nginx start # commands: stop, status, reload Test config \u00b6 sudo nginx -t View process \u00b6 ps -ef |grep nginx View logs \u00b6 ls /var/log/nginx/ Config \u00b6 Config file location \u00b6 /etc/nginx/nginx.conf /etc/nginx/sites-enabled/default Keywords \u00b6 listen: port to listen server_name: host or domin root: site root directory location: route index Config sample \u00b6 Static website server server { listen 80; server_name 10.10.10.10; root /{app_root_directory}/; index index.html; } Dynamic website server server { listen 80 ; server_name 10 .10.10.10 ; location / { proxy_pass { dynamic server url } ; # sample: proxy_pass http://127.0.0.1:5500 } } Add static resource location /static/ { root /{app_static_directory}/; } Debug \u00b6 403 Error \u00b6 Maybe file permission problem, increase Nginx permsision or set user at nginx.conf, or decrease target files permission. Referral \u00b6 Nginx Offcial Document","title":"Nginx"},{"location":"server/nginx/#nginx","text":"","title":"Nginx"},{"location":"server/nginx/#install","text":"Install on Ubuntu sudo apt-get update sudo apt-get install nginx Version check nginx -v","title":"Install"},{"location":"server/nginx/#admin","text":"","title":"Admin"},{"location":"server/nginx/#start-server","text":"sudo /etc/init.d/nginx start # or sudo /usr/local/nginx/sbin/nginx # or sudo service nginx start # commands: stop, status, reload","title":"Start server"},{"location":"server/nginx/#test-config","text":"sudo nginx -t","title":"Test config"},{"location":"server/nginx/#view-process","text":"ps -ef |grep nginx","title":"View process"},{"location":"server/nginx/#view-logs","text":"ls /var/log/nginx/","title":"View logs"},{"location":"server/nginx/#config","text":"","title":"Config"},{"location":"server/nginx/#config-file-location","text":"/etc/nginx/nginx.conf /etc/nginx/sites-enabled/default","title":"Config file location"},{"location":"server/nginx/#keywords","text":"listen: port to listen server_name: host or domin root: site root directory location: route index","title":"Keywords"},{"location":"server/nginx/#config-sample","text":"Static website server server { listen 80; server_name 10.10.10.10; root /{app_root_directory}/; index index.html; } Dynamic website server server { listen 80 ; server_name 10 .10.10.10 ; location / { proxy_pass { dynamic server url } ; # sample: proxy_pass http://127.0.0.1:5500 } } Add static resource location /static/ { root /{app_static_directory}/; }","title":"Config sample"},{"location":"server/nginx/#debug","text":"","title":"Debug"},{"location":"server/nginx/#403-error","text":"Maybe file permission problem, increase Nginx permsision or set user at nginx.conf, or decrease target files permission.","title":"403 Error"},{"location":"server/nginx/#referral","text":"Nginx Offcial Document","title":"Referral"},{"location":"server/restfulapi/","text":"REST \u00b6 \"What is REST?\" from https://restfulapi.net/ Flask restful \u00b6 How to create a new api? \u00b6 1. Create a API app \u00b6 from flask_restful import Resource , Api app = Flask ( __name__ ) api = Api ( app ) 2. Create a view inherit from flask_restful.Resource \u00b6 class HelloWorld ( Resource ): def get ( self ): return { 'hello' : 'world' } 3. Regist view to the urls \u00b6 api . add_resource ( HelloWorld , '/' ) End Django Restframework \u00b6 How to create a new api? \u00b6 1. Serialize model in serializers.py \u00b6 from rest_framework import serializers from newapp.models import ModelX class ModelXSerializer ( serializers . HyperlinkedModelSerializer ): class Meta : ModelX = ModelX fields = ( 'name' , 'email' ) 2. Create API view in view.py \u00b6 from rest_framework import viewsets from newapp.models import ModelX from newapp.serializers import ModelXSerializer class ModelXViewSet ( viewsets . ModelViewSet ): # Sorting can be set here. queryset = ModelX . objects . all () . order_by ( '-date' ) serializer_class = ModelXSerializer 3. Regist view to urls in urls.py \u00b6 from django.urls import include , path from rest_framework import routers from newapp import views router = routers . DefaultRouter () router . register ( 'api-path' , views . ModelXViewSet ) End Referral \u00b6 Flask restful quick start Django Rest framework quick start","title":"RestfulAPI"},{"location":"server/restfulapi/#rest","text":"\"What is REST?\" from https://restfulapi.net/","title":"REST"},{"location":"server/restfulapi/#flask-restful","text":"","title":"Flask restful"},{"location":"server/restfulapi/#how-to-create-a-new-api","text":"","title":"How to create a new api?"},{"location":"server/restfulapi/#1-create-a-api-app","text":"from flask_restful import Resource , Api app = Flask ( __name__ ) api = Api ( app )","title":"1. Create a API app"},{"location":"server/restfulapi/#2-create-a-view-inherit-from-flask_restfulresource","text":"class HelloWorld ( Resource ): def get ( self ): return { 'hello' : 'world' }","title":"2. Create a view inherit from flask_restful.Resource"},{"location":"server/restfulapi/#3-regist-view-to-the-urls","text":"api . add_resource ( HelloWorld , '/' ) End","title":"3. Regist view to the urls"},{"location":"server/restfulapi/#django-restframework","text":"","title":"Django Restframework"},{"location":"server/restfulapi/#how-to-create-a-new-api_1","text":"","title":"How to create a new api?"},{"location":"server/restfulapi/#1-serialize-model-in-serializerspy","text":"from rest_framework import serializers from newapp.models import ModelX class ModelXSerializer ( serializers . HyperlinkedModelSerializer ): class Meta : ModelX = ModelX fields = ( 'name' , 'email' )","title":"1. Serialize model in serializers.py"},{"location":"server/restfulapi/#2-create-api-view-in-viewpy","text":"from rest_framework import viewsets from newapp.models import ModelX from newapp.serializers import ModelXSerializer class ModelXViewSet ( viewsets . ModelViewSet ): # Sorting can be set here. queryset = ModelX . objects . all () . order_by ( '-date' ) serializer_class = ModelXSerializer","title":"2. Create API view in view.py"},{"location":"server/restfulapi/#3-regist-view-to-urls-in-urlspy","text":"from django.urls import include , path from rest_framework import routers from newapp import views router = routers . DefaultRouter () router . register ( 'api-path' , views . ModelXViewSet ) End","title":"3. Regist view to urls in urls.py"},{"location":"server/restfulapi/#referral","text":"Flask restful quick start Django Rest framework quick start","title":"Referral"},{"location":"server/scrapy/","text":"Scrapy \u00b6 Start spider \u00b6 scrapy startproject {spide name} Spider script sample: \u00b6 import scrapy from SpiderName.items import ItemModel class SpiderName ( scrapy . Spider ): name = \"SpiderName\" def start_requests ( self ): urls = [ \"url1\" , \"url2\" ] for url in urls : yield scrapy . Request ( url = url , callback = self . parse ) def parse ( self , response ): # response.css can query html page content # response.url can get request url data = response . css ({ pattern }) item = ItemModel ( data ) yield item Pipeline Sample \u00b6 import mysql.connector import configparser class OpentrendPipeline ( object ): def process_item ( self , item , spider ): print ( item ) return item class MysqlPipeline ( object ): def __init__ ( self ): pass def open_spider ( self , spider ): config = configparser . ConfigParser () config . read ( 'config.ini' ) self . conn = mysql . connector . connect ( host = config [ 'DATABASE' ][ \"host\" ], port = int ( config [ 'DATABASE' ][ \"port\" ]), user = config [ 'DATABASE' ][ \"user\" ], password = config [ 'DATABASE' ][ \"password\" ]) cur = self . conn . cursor () cur . execute ( \"CREATE DATABASE IF NOT EXISTS sea\" ) self . conn . commit () cur . execute ( TABLE_CREATE_SQL ) self . conn . commit () def close_spider ( self , spider ): self . conn . commit () self . conn . close () def process_item ( self , item , spider ): addRow = ( \"INSERT INTO sea.opentrend \" \"(name,language,description,total_star_count,fork_count,member_count,period_stars_count,period,created_dt) \" \"VALUES ( %(name)s , %(language)s , %(description)s , %(total_star_count)s , %(fork_count)s , %(member_count)s , %(period_stars_count)s , %(period)s , %(created_dt)s )\" ) cur = self . conn . cursor () cur . execute ( addRow , dict ( item ))","title":"Scrapy"},{"location":"server/scrapy/#scrapy","text":"","title":"Scrapy"},{"location":"server/scrapy/#start-spider","text":"scrapy startproject {spide name}","title":"Start spider"},{"location":"server/scrapy/#spider-script-sample","text":"import scrapy from SpiderName.items import ItemModel class SpiderName ( scrapy . Spider ): name = \"SpiderName\" def start_requests ( self ): urls = [ \"url1\" , \"url2\" ] for url in urls : yield scrapy . Request ( url = url , callback = self . parse ) def parse ( self , response ): # response.css can query html page content # response.url can get request url data = response . css ({ pattern }) item = ItemModel ( data ) yield item","title":"Spider script sample:"},{"location":"server/scrapy/#pipeline-sample","text":"import mysql.connector import configparser class OpentrendPipeline ( object ): def process_item ( self , item , spider ): print ( item ) return item class MysqlPipeline ( object ): def __init__ ( self ): pass def open_spider ( self , spider ): config = configparser . ConfigParser () config . read ( 'config.ini' ) self . conn = mysql . connector . connect ( host = config [ 'DATABASE' ][ \"host\" ], port = int ( config [ 'DATABASE' ][ \"port\" ]), user = config [ 'DATABASE' ][ \"user\" ], password = config [ 'DATABASE' ][ \"password\" ]) cur = self . conn . cursor () cur . execute ( \"CREATE DATABASE IF NOT EXISTS sea\" ) self . conn . commit () cur . execute ( TABLE_CREATE_SQL ) self . conn . commit () def close_spider ( self , spider ): self . conn . commit () self . conn . close () def process_item ( self , item , spider ): addRow = ( \"INSERT INTO sea.opentrend \" \"(name,language,description,total_star_count,fork_count,member_count,period_stars_count,period,created_dt) \" \"VALUES ( %(name)s , %(language)s , %(description)s , %(total_star_count)s , %(fork_count)s , %(member_count)s , %(period_stars_count)s , %(period)s , %(created_dt)s )\" ) cur = self . conn . cursor () cur . execute ( addRow , dict ( item ))","title":"Pipeline Sample"},{"location":"server/streamlit/","text":"Streamlit \u00b6 Setup \u00b6 import streamlit as st Featrues \u00b6 titel: st.title('{title}') side bar: multi select: st.sidebar.multiselect ratio: st.sidebar.radio text(support markdown, dataframe): st.write('{text}') plot chart: st.plotly_chart({fig})","title":"Streamlit"},{"location":"server/streamlit/#streamlit","text":"","title":"Streamlit"},{"location":"server/streamlit/#setup","text":"import streamlit as st","title":"Setup"},{"location":"server/streamlit/#featrues","text":"titel: st.title('{title}') side bar: multi select: st.sidebar.multiselect ratio: st.sidebar.radio text(support markdown, dataframe): st.write('{text}') plot chart: st.plotly_chart({fig})","title":"Featrues"},{"location":"server/supervisor/","text":"Supervisor \u00b6 Install \u00b6 pip install supervisor Admin \u00b6 Start \u00b6 # In config directory cd /etc/supervisor/ supervisord If start multiple supervisor task accidently, kill process find in ps -ef . Command tool \u00b6 # run supervisorctl # shutdown supervisorctl shutdown Config \u00b6 File location: /etc/supervisor/supervisord.conf Config Sample [ supervisord ] [ supervisorctl ] [ program:foo ] command = /root/projects/servertest/env/bin/python /root/projects/servertest/manage.py runserver Debug \u00b6 Execute faild \u00b6 Permission related","title":"Supervisor"},{"location":"server/supervisor/#supervisor","text":"","title":"Supervisor"},{"location":"server/supervisor/#install","text":"pip install supervisor","title":"Install"},{"location":"server/supervisor/#admin","text":"","title":"Admin"},{"location":"server/supervisor/#start","text":"# In config directory cd /etc/supervisor/ supervisord If start multiple supervisor task accidently, kill process find in ps -ef .","title":"Start"},{"location":"server/supervisor/#command-tool","text":"# run supervisorctl # shutdown supervisorctl shutdown","title":"Command tool"},{"location":"server/supervisor/#config","text":"File location: /etc/supervisor/supervisord.conf Config Sample [ supervisord ] [ supervisorctl ] [ program:foo ] command = /root/projects/servertest/env/bin/python /root/projects/servertest/manage.py runserver","title":"Config"},{"location":"server/supervisor/#debug","text":"","title":"Debug"},{"location":"server/supervisor/#execute-faild","text":"Permission related","title":"Execute faild"}]}